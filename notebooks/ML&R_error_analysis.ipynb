{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML&R_error_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K6NYTcAvln4J",
        "YHxUZWqils8I"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6NYTcAvln4J"
      },
      "source": [
        "### Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaNZqkhqfjiJ",
        "outputId": "f8c645bb-a05f-469e-fe11-fbb003b08115"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/Machine Learning and Reasoning/'\n",
        "DATA_PATH = PATH + 'Data/'\n",
        "RESULTS_PATH = PATH + 'Results/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxUZWqils8I"
      },
      "source": [
        "### Clone github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKol2g8WU1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4691ae2-43c3-45b7-e2bf-c36e77a21531"
      },
      "source": [
        "git_username = ''\n",
        "git_token =  ''\n",
        "\n",
        "if git_username == '':\n",
        "  print('Github username:')\n",
        "  git_username = %sx read -p ''\n",
        "  git_username = git_username[0]\n",
        "\n",
        "if git_token == '':\n",
        "  print('Github access token (https://github.com/settings/tokens):')\n",
        "  print('Github Token:')\n",
        "  git_token = %sx read -p ''\n",
        "  git_token = git_token[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Github username:\n",
            "Github access token (https://github.com/settings/tokens):\n",
            "Github Token:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA6Ej0xOjzbu",
        "outputId": "eb3ffbad-a049-4b5c-eb11-42cee61df91f"
      },
      "source": [
        "# Clone the entire repo.\n",
        "%cd /content\n",
        "!git clone -l -s https://$git_username:$git_token@github.com/Pawel-M/Machine-Learning-and-Reasoning.git machine-learning-and-reasoning\n",
        "%cd machine-learning-and-reasoning\n",
        "!ls\n",
        "!git init\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'machine-learning-and-reasoning' already exists and is not an empty directory.\n",
            "/content/machine-learning-and-reasoning\n",
            "analysis  dataset  models  notebooks  README.md  results\n",
            "Reinitialized existing Git repository in /content/machine-learning-and-reasoning/.git/\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRNClFZAZrTP",
        "outputId": "fb55567f-485e-4631-ece6-bda0abbf0d3d"
      },
      "source": [
        "# Update the entire repo.\n",
        "%cd /content\n",
        "%cd machine-learning-and-reasoning\n",
        "!git pull\n",
        "!ls\n",
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/machine-learning-and-reasoning\n",
            "remote: Invalid username or password.\n",
            "fatal: Authentication failed for 'https://GitHubByJelle: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@github.com/Pawel-M/Machine-Learning-and-Reasoning.git/'\n",
            "analysis  dataset  models  notebooks  README.md  results\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmfy2j6FkjLo",
        "outputId": "71272fe5-7641-4b28-ef02-baa274e6ad5d"
      },
      "source": [
        "import sys\n",
        "\n",
        "REPO_PATH = '/content/machine-learning-and-reasoning'\n",
        "\n",
        "sys.path.append(REPO_PATH)\n",
        "print(sys.path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/machine-learning-and-reasoning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGHJYwjUJ7Ge"
      },
      "source": [
        "### Create dataset and save it to your Drive\n",
        "\n",
        "** Copy dataset files from our Google Drive (they are in \"Dataset\" folder) to \"Colab Notebooks/Machine Learning and Reasoning/Data\" folder. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPsnGRZHKANI"
      },
      "source": [
        "# from dataset.generation import generate_and_save_trees, test_for_guarantees_true\n",
        "# from dataset.encoding import encode_trees\n",
        "\n",
        "# max_depth = 2\n",
        "# num_variables = 5\n",
        "# input_length = 10\n",
        "# output_length = 5\n",
        "# print('Creating trees...')\n",
        "# generate_and_save_trees(DATA_PATH, num_generations=1000000,\n",
        "#                         max_depth=max_depth, num_variables=num_variables,\n",
        "#                         test_fn=test_for_guarantees_true,\n",
        "#                         load_existing=True, print_every=10000)\n",
        "\n",
        "# print('Encoding trees...')\n",
        "# encode_trees(DATA_PATH, \n",
        "#              max_depth=max_depth, num_variables=num_variables, \n",
        "#              prefix=False, input_length=input_length, output_length=output_length)\n",
        "\n",
        "# print('Dataset saved.')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NTfnysd6TDj"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "# Experiments\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbok4hOM1tP"
      },
      "source": [
        "## Simple Models training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRyMOq1gUepb",
        "outputId": "19c4d181-41d1-4430-aa52-af738b59e542"
      },
      "source": [
        "from dataset.common import get_dataset\n",
        "from models.rnn_example import create_simple_rnn_model, create_lstm_model, create_gru_model\n",
        "\n",
        "depth = 2\n",
        "variables = 5\n",
        "\n",
        "model_fn = create_gru_model\n",
        "base_name = 'gru'\n",
        "model_args = {\n",
        "    'num_layers': 1,\n",
        "    'embedding_size': 64,\n",
        "    'hidden_units': 128,\n",
        "    'bidirectional': True,\n",
        "}\n",
        "training_args = {\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 64,\n",
        "    'epochs': 300,\n",
        "    'patience': 10,\n",
        "    'min_delta': 1e-4,\n",
        "}\n",
        "\n",
        "\n",
        "data = get_dataset(DATA_PATH, depth=depth, variables=variables, \n",
        "                      test_size=.1, valid_size=.1, indexed_encoding=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 0 ... 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zevy5_SGuIoI"
      },
      "source": [
        "import tensorflow.keras as kr\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def train_model_pred(model, dataset, learning_rate, batch_size, epochs, patience=None, min_delta=0.):\n",
        "    model.compile(optimizer=kr.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss=kr.losses.categorical_crossentropy,\n",
        "                  metrics=['categorical_accuracy'])\n",
        "\n",
        "    callbacks = []\n",
        "    if patience is not None:\n",
        "        assert dataset.x_valid is not None or dataset.y_valid is not None, \\\n",
        "            \"Validation subset must not be empty when using early stopping.\"\n",
        "        callbacks.append(kr.callbacks.EarlyStopping(patience=patience,\n",
        "                                                    min_delta=min_delta,\n",
        "                                                    restore_best_weights=True,\n",
        "                                                    verbose=1))\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(dataset.x_train, dataset.y_train, validation_data=(dataset.x_valid, dataset.y_valid),\n",
        "                        batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f'Training time: {(end_time - start_time):.1f}s')\n",
        "    pred = model.predict(dataset.x_test)\n",
        "    test_accuracy = np.mean(kr.metrics.categorical_accuracy(dataset.y_test, pred))\n",
        "    print(f'Test accuracy: {test_accuracy * 100:.1f} %')\n",
        "    return pred"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SfsrUeCZLf2",
        "outputId": "f377bc5c-9b01-4c46-ee35-dcecb0c4a63d"
      },
      "source": [
        "if 'input_dim' not in model_args:\n",
        "    if data.indexed_encoding:\n",
        "        model_args['input_dim'] = np.max(data.x_train)\n",
        "    else:\n",
        "        model_args['input_dim'] = data.x_train.shape[-1]\n",
        "\n",
        "if 'output_dim' not in model_args:\n",
        "  model_args['output_dim'] = data.y_train.shape[-1]\n",
        "\n",
        "model = model_fn(**model_args)\n",
        "pred = train_model_pred(model, data, **training_args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          704       \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               148992    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 150,981\n",
            "Trainable params: 150,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "18/18 [==============================] - 12s 189ms/step - loss: 1.5970 - categorical_accuracy: 0.2864 - val_loss: 1.5232 - val_categorical_accuracy: 0.6480\n",
            "Epoch 2/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 1.4368 - categorical_accuracy: 0.6521 - val_loss: 0.8905 - val_categorical_accuracy: 0.6880\n",
            "Epoch 3/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.7589 - categorical_accuracy: 0.7322 - val_loss: 0.4336 - val_categorical_accuracy: 0.8400\n",
            "Epoch 4/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4756 - categorical_accuracy: 0.8270 - val_loss: 0.3707 - val_categorical_accuracy: 0.8720\n",
            "Epoch 5/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4146 - categorical_accuracy: 0.8540 - val_loss: 0.2866 - val_categorical_accuracy: 0.8800\n",
            "Epoch 6/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3594 - categorical_accuracy: 0.8681 - val_loss: 0.2696 - val_categorical_accuracy: 0.8880\n",
            "Epoch 7/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3545 - categorical_accuracy: 0.8706 - val_loss: 0.2659 - val_categorical_accuracy: 0.8960\n",
            "Epoch 8/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3509 - categorical_accuracy: 0.8755 - val_loss: 0.2679 - val_categorical_accuracy: 0.8960\n",
            "Epoch 9/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3554 - categorical_accuracy: 0.8606 - val_loss: 0.2530 - val_categorical_accuracy: 0.8800\n",
            "Epoch 10/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3411 - categorical_accuracy: 0.8810 - val_loss: 0.2407 - val_categorical_accuracy: 0.8960\n",
            "Epoch 11/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3296 - categorical_accuracy: 0.8847 - val_loss: 0.2430 - val_categorical_accuracy: 0.8880\n",
            "Epoch 12/300\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3268 - categorical_accuracy: 0.8809 - val_loss: 0.2469 - val_categorical_accuracy: 0.8880\n",
            "Epoch 13/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3313 - categorical_accuracy: 0.8865 - val_loss: 0.2324 - val_categorical_accuracy: 0.9120\n",
            "Epoch 14/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3109 - categorical_accuracy: 0.8871 - val_loss: 0.2398 - val_categorical_accuracy: 0.9120\n",
            "Epoch 15/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3066 - categorical_accuracy: 0.8932 - val_loss: 0.2087 - val_categorical_accuracy: 0.9200\n",
            "Epoch 16/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.2737 - categorical_accuracy: 0.9014 - val_loss: 0.2478 - val_categorical_accuracy: 0.9200\n",
            "Epoch 17/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.2733 - categorical_accuracy: 0.9051 - val_loss: 0.1917 - val_categorical_accuracy: 0.9440\n",
            "Epoch 18/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.2622 - categorical_accuracy: 0.9130 - val_loss: 0.2810 - val_categorical_accuracy: 0.9040\n",
            "Epoch 19/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3055 - categorical_accuracy: 0.8850 - val_loss: 0.1757 - val_categorical_accuracy: 0.9440\n",
            "Epoch 20/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.2872 - categorical_accuracy: 0.9153 - val_loss: 0.1741 - val_categorical_accuracy: 0.9440\n",
            "Epoch 21/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.2241 - categorical_accuracy: 0.9413 - val_loss: 0.1655 - val_categorical_accuracy: 0.9440\n",
            "Epoch 22/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.2163 - categorical_accuracy: 0.9374 - val_loss: 0.1456 - val_categorical_accuracy: 0.9680\n",
            "Epoch 23/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1982 - categorical_accuracy: 0.9377 - val_loss: 0.1842 - val_categorical_accuracy: 0.9360\n",
            "Epoch 24/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.1858 - categorical_accuracy: 0.9419 - val_loss: 0.1382 - val_categorical_accuracy: 0.9760\n",
            "Epoch 25/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1440 - categorical_accuracy: 0.9678 - val_loss: 0.1193 - val_categorical_accuracy: 0.9680\n",
            "Epoch 26/300\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.1642 - categorical_accuracy: 0.9473 - val_loss: 0.1037 - val_categorical_accuracy: 0.9840\n",
            "Epoch 27/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.1523 - categorical_accuracy: 0.9532 - val_loss: 0.2085 - val_categorical_accuracy: 0.9280\n",
            "Epoch 28/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1675 - categorical_accuracy: 0.9395 - val_loss: 0.1082 - val_categorical_accuracy: 0.9680\n",
            "Epoch 29/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.1415 - categorical_accuracy: 0.9504 - val_loss: 0.0762 - val_categorical_accuracy: 0.9680\n",
            "Epoch 30/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1067 - categorical_accuracy: 0.9576 - val_loss: 0.0716 - val_categorical_accuracy: 0.9760\n",
            "Epoch 31/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1187 - categorical_accuracy: 0.9555 - val_loss: 0.0567 - val_categorical_accuracy: 0.9840\n",
            "Epoch 32/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0890 - categorical_accuracy: 0.9638 - val_loss: 0.0501 - val_categorical_accuracy: 0.9840\n",
            "Epoch 33/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.1079 - categorical_accuracy: 0.9475 - val_loss: 0.0540 - val_categorical_accuracy: 0.9840\n",
            "Epoch 34/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0861 - categorical_accuracy: 0.9618 - val_loss: 0.0462 - val_categorical_accuracy: 0.9920\n",
            "Epoch 35/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0899 - categorical_accuracy: 0.9541 - val_loss: 0.0574 - val_categorical_accuracy: 0.9760\n",
            "Epoch 36/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0703 - categorical_accuracy: 0.9715 - val_loss: 0.0626 - val_categorical_accuracy: 0.9760\n",
            "Epoch 37/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0828 - categorical_accuracy: 0.9620 - val_loss: 0.0423 - val_categorical_accuracy: 0.9840\n",
            "Epoch 38/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0854 - categorical_accuracy: 0.9573 - val_loss: 0.1689 - val_categorical_accuracy: 0.9360\n",
            "Epoch 39/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0917 - categorical_accuracy: 0.9499 - val_loss: 0.0600 - val_categorical_accuracy: 0.9680\n",
            "Epoch 40/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0846 - categorical_accuracy: 0.9580 - val_loss: 0.0508 - val_categorical_accuracy: 0.9760\n",
            "Epoch 41/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0778 - categorical_accuracy: 0.9619 - val_loss: 0.0488 - val_categorical_accuracy: 0.9760\n",
            "Epoch 42/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0755 - categorical_accuracy: 0.9599 - val_loss: 0.0694 - val_categorical_accuracy: 0.9760\n",
            "Epoch 43/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0841 - categorical_accuracy: 0.9626 - val_loss: 0.0446 - val_categorical_accuracy: 0.9840\n",
            "Epoch 44/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0712 - categorical_accuracy: 0.9713 - val_loss: 0.0560 - val_categorical_accuracy: 0.9680\n",
            "Epoch 45/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0604 - categorical_accuracy: 0.9750 - val_loss: 0.0314 - val_categorical_accuracy: 0.9920\n",
            "Epoch 46/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0754 - categorical_accuracy: 0.9608 - val_loss: 0.0325 - val_categorical_accuracy: 0.9840\n",
            "Epoch 47/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0551 - categorical_accuracy: 0.9728 - val_loss: 0.0543 - val_categorical_accuracy: 0.9760\n",
            "Epoch 48/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0568 - categorical_accuracy: 0.9757 - val_loss: 0.0363 - val_categorical_accuracy: 0.9920\n",
            "Epoch 49/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0591 - categorical_accuracy: 0.9748 - val_loss: 0.0371 - val_categorical_accuracy: 0.9840\n",
            "Epoch 50/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0536 - categorical_accuracy: 0.9736 - val_loss: 0.0310 - val_categorical_accuracy: 0.9840\n",
            "Epoch 51/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0434 - categorical_accuracy: 0.9826 - val_loss: 0.0472 - val_categorical_accuracy: 0.9840\n",
            "Epoch 52/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0467 - categorical_accuracy: 0.9770 - val_loss: 0.0290 - val_categorical_accuracy: 0.9920\n",
            "Epoch 53/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0575 - categorical_accuracy: 0.9742 - val_loss: 0.0467 - val_categorical_accuracy: 0.9680\n",
            "Epoch 54/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0381 - categorical_accuracy: 0.9856 - val_loss: 0.0355 - val_categorical_accuracy: 0.9840\n",
            "Epoch 55/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0337 - categorical_accuracy: 0.9846 - val_loss: 0.0300 - val_categorical_accuracy: 0.9840\n",
            "Epoch 56/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0278 - categorical_accuracy: 0.9900 - val_loss: 0.0288 - val_categorical_accuracy: 0.9840\n",
            "Epoch 57/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0328 - categorical_accuracy: 0.9893 - val_loss: 0.0294 - val_categorical_accuracy: 0.9920\n",
            "Epoch 58/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0383 - categorical_accuracy: 0.9839 - val_loss: 0.0452 - val_categorical_accuracy: 0.9760\n",
            "Epoch 59/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0314 - categorical_accuracy: 0.9922 - val_loss: 0.0363 - val_categorical_accuracy: 0.9760\n",
            "Epoch 60/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0283 - categorical_accuracy: 0.9961 - val_loss: 0.0276 - val_categorical_accuracy: 0.9920\n",
            "Epoch 61/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0261 - categorical_accuracy: 0.9957 - val_loss: 0.0304 - val_categorical_accuracy: 0.9840\n",
            "Epoch 62/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0190 - categorical_accuracy: 0.9933 - val_loss: 0.0344 - val_categorical_accuracy: 0.9920\n",
            "Epoch 63/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0155 - categorical_accuracy: 0.9958 - val_loss: 0.0372 - val_categorical_accuracy: 0.9680\n",
            "Epoch 64/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0141 - categorical_accuracy: 0.9974 - val_loss: 0.0288 - val_categorical_accuracy: 0.9920\n",
            "Epoch 65/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0151 - categorical_accuracy: 0.9946 - val_loss: 0.0334 - val_categorical_accuracy: 0.9840\n",
            "Epoch 66/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0129 - categorical_accuracy: 0.9990 - val_loss: 0.0270 - val_categorical_accuracy: 0.9920\n",
            "Epoch 67/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0110 - categorical_accuracy: 0.9977 - val_loss: 0.0262 - val_categorical_accuracy: 0.9920\n",
            "Epoch 68/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0102 - categorical_accuracy: 1.0000 - val_loss: 0.0234 - val_categorical_accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0093 - categorical_accuracy: 0.9994 - val_loss: 0.0233 - val_categorical_accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0098 - categorical_accuracy: 1.0000 - val_loss: 0.0192 - val_categorical_accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0093 - categorical_accuracy: 1.0000 - val_loss: 0.0221 - val_categorical_accuracy: 0.9920\n",
            "Epoch 72/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0075 - categorical_accuracy: 1.0000 - val_loss: 0.0209 - val_categorical_accuracy: 0.9920\n",
            "Epoch 73/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 0.0201 - val_categorical_accuracy: 0.9920\n",
            "Epoch 74/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 0.0187 - val_categorical_accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0063 - categorical_accuracy: 0.9996 - val_loss: 0.0198 - val_categorical_accuracy: 0.9920\n",
            "Epoch 76/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 0.0184 - val_categorical_accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0050 - categorical_accuracy: 0.9994 - val_loss: 0.0169 - val_categorical_accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0055 - categorical_accuracy: 1.0000 - val_loss: 0.0158 - val_categorical_accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 0.0154 - val_categorical_accuracy: 1.0000\n",
            "Epoch 81/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.0146 - val_categorical_accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 0.0143 - val_categorical_accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.0137 - val_categorical_accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.0142 - val_categorical_accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.0131 - val_categorical_accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0035 - categorical_accuracy: 1.0000 - val_loss: 0.0132 - val_categorical_accuracy: 1.0000\n",
            "Epoch 87/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.0122 - val_categorical_accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 0.0126 - val_categorical_accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0033 - categorical_accuracy: 1.0000 - val_loss: 0.0119 - val_categorical_accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 0.0117 - val_categorical_accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0024 - categorical_accuracy: 1.0000 - val_loss: 0.0114 - val_categorical_accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 0.0112 - val_categorical_accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.0115 - val_categorical_accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 0.0108 - val_categorical_accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.0107 - val_categorical_accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.0099 - val_categorical_accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.0098 - val_categorical_accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.0091 - val_categorical_accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0100 - val_categorical_accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0093 - val_categorical_accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0086 - val_categorical_accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0088 - val_categorical_accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0088 - val_categorical_accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0083 - val_categorical_accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.0079 - val_categorical_accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0082 - val_categorical_accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0078 - val_categorical_accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0074 - val_categorical_accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0075 - val_categorical_accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.8749e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0070 - val_categorical_accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 7.6312e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0069 - val_categorical_accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 8.2834e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0071 - val_categorical_accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 7.6829e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0064 - val_categorical_accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 8.4752e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0065 - val_categorical_accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.0062 - val_categorical_accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.6561e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0063 - val_categorical_accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 7.0351e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0064 - val_categorical_accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.7619e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_categorical_accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.9065e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0059 - val_categorical_accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.5983e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0057 - val_categorical_accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 5.8125e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0058 - val_categorical_accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 8.0697e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_categorical_accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 7.3202e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_categorical_accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 6.7345e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0054 - val_categorical_accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 6.8108e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0053 - val_categorical_accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 5.8872e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0052 - val_categorical_accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 5.3183e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_categorical_accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 5.0688e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0049 - val_categorical_accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 6.2989e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_categorical_accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 7.4144e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0048 - val_categorical_accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 4.9306e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_categorical_accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 6.0632e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0046 - val_categorical_accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 5.0621e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_categorical_accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 4.7553e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0043 - val_categorical_accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 4.2039e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0044 - val_categorical_accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 3.9678e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_categorical_accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 5.9605e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0040 - val_categorical_accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 4.4629e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0039 - val_categorical_accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 4.0521e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0038 - val_categorical_accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 3.4270e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0038 - val_categorical_accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 3.6184e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0037 - val_categorical_accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 4.2414e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0037 - val_categorical_accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 3.5954e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0037 - val_categorical_accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 3.6765e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0038 - val_categorical_accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 4.2059e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0036 - val_categorical_accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.8731e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0033 - val_categorical_accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 3.0897e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0035 - val_categorical_accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.7091e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0035 - val_categorical_accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 4.2076e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0033 - val_categorical_accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 3.6500e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0033 - val_categorical_accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 3.1062e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0032 - val_categorical_accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 2.8678e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0031 - val_categorical_accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.4391e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0032 - val_categorical_accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.5677e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0031 - val_categorical_accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 3.4881e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0031 - val_categorical_accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.3280e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0030 - val_categorical_accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 3.0877e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0030 - val_categorical_accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.7574e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.2758e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.3568e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.1622e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.4536e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.9730e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.4535e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.0481e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 2.1242e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0028 - val_categorical_accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.9936e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.8669e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.9836e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.1532e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.0902e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.8600e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0024 - val_categorical_accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.7069e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0025 - val_categorical_accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.6666e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0024 - val_categorical_accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.3372e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0024 - val_categorical_accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.2847e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0024 - val_categorical_accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.4875e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.3985e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.9564e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.9528e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.6874e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.9615e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0023 - val_categorical_accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.6852e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0022 - val_categorical_accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.6423e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.8648e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.4979e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.7897e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.4938e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.4222e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0021 - val_categorical_accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.4961e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.3991e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.5379e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.3426e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0020 - val_categorical_accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.2187e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.5448e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.2814e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.6082e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.3320e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 1.0662e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.3073e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0019 - val_categorical_accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.2067e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.3809e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 1.3338e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0018 - val_categorical_accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 8.1545e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 7.8859e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 9.5818e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.2185e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 9.1595e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 9.9950e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 8.7481e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 9.5957e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0017 - val_categorical_accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.3862e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 7.3954e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.0028e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.0318e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.2310e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0016 - val_categorical_accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 1.0587e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 1.0270e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 6.8688e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 9.1697e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 8.6084e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 8.7808e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0015 - val_categorical_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00222: early stopping\n",
            "Training time: 101.7s\n",
            "Test accuracy: 97.8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq8xM6VViVlV"
      },
      "source": [
        "## Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NCCyOqaop5uK",
        "outputId": "6082dd5d-d083-4712-de51-e02dcea3f69a"
      },
      "source": [
        "import dataset.encoding\n",
        "\n",
        "dec_input_dict, dec_output_dict = dataset.encoding.create_decoding_dictionaries(data.input_dictionary, \n",
        "                                                                                data.output_dictionary)\n",
        "\n",
        "dataset.encoding.decode_sentence(data.x_test[0], dec_input_dict, indexed_encoding=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( ( 1 or 1 ) and ( 2 or 1 ) )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orWZ_9ksZcVx",
        "outputId": "d839f749-bb85-4864-d5f9-ececba9bf16f"
      },
      "source": [
        "# Get params that are predicted wrong\n",
        "index = kr.metrics.categorical_accuracy(data.y_test, pred) == 0\n",
        "index"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(138,), dtype=bool, numpy=\n",
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yhrw1Csa740",
        "outputId": "7fb95745-f6e6-4d14-fda5-22023b698b5d"
      },
      "source": [
        "# Make function that converts the probabilities to binary\n",
        "def get_answer(pred):\n",
        "  binary = []\n",
        "  for i, row in enumerate(pred):\n",
        "    binary.append([1 if x == max(pred[i]) else 0 for x in row])\n",
        "  return np.array(binary)\n",
        "\n",
        "get_answer(pred[index])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TFpwf7nUce4b",
        "outputId": "a39d9389-ea6c-442b-c5b4-358f369b189c"
      },
      "source": [
        "# Look at all the individual mistakes\n",
        "import pandas as pd\n",
        "\n",
        "sentences = [dataset.encoding.decode_sentence(x, dec_input_dict,\n",
        "                                              indexed_encoding=True) for x in data.x_test[index]]\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data={\"Sentence\":sentences,\n",
        "                        \"True\":data.y_test[index].argmax(axis=1),\n",
        "                        \"Predicted\":get_answer(pred[index]).argmax(axis=1),\n",
        "                        \"Probability\":pred[index].max(axis=1)})\n",
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>True</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>not not 5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.462316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>( ( 2 or 3 ) and not 2 )</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.881510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>( ( 3 or 2 ) and not 3 )</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.570150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Sentence  True  Predicted  Probability\n",
              "0                 not not 5     4          3     0.462316\n",
              "1  ( ( 2 or 3 ) and not 2 )     2          1     0.881510\n",
              "2  ( ( 3 or 2 ) and not 3 )     1          2     0.570150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sCIJWM5nlRcX",
        "outputId": "9c5b8343-6c3e-48ba-e8c0-59716ed0f3a9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Look at all predictions\n",
        "df_all = pd.DataFrame(data={\"True\":data.y_test.argmax(axis=1),\n",
        "                        \"Predicted\":get_answer(pred).argmax(axis=1),\n",
        "                        \"Probability\":pred.max(axis=1)})\n",
        "\n",
        "barlist = plt.bar(df_all.index, df_all.Probability)\n",
        "for ind in df_all.index[index]:\n",
        "  barlist[ind].set_color('r')\n",
        "plt.title(\"Probability landscape\")\n",
        "plt.xlabel(\"Sentence\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nn3ef3N-eBii",
        "outputId": "5b56762c-0fe0-4c94-94b0-5b76a3f577fc"
      },
      "source": [
        "# Confusion matrix - all\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "cm = confusion_matrix(data.y_test.argmax(axis=1),\n",
        "                      get_answer(pred).argmax(axis=1))\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in \"ABCDE\"],\n",
        "                  columns = [i for i in \"ABCDE\"])\n",
        "sn.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jzzQGqNBiseU",
        "outputId": "82c5a350-6e26-40de-e8fe-a8116047ecf1"
      },
      "source": [
        "# Look at input ? All of them multiple variables?\n",
        "# Count number of variables\n",
        "# Count amounts of and / or / not\n",
        "\n",
        "sentences = [dataset.encoding.decode_sentence(x, dec_input_dict,\n",
        "                                              indexed_encoding=True) for x in data.x_test]\n",
        "\n",
        "sen_vars = (data.x_test <= 5) & (data.x_test > 0)\n",
        "sen_and = data.x_test == 9 \n",
        "sen_or = data.x_test == 10\n",
        "sen_not = data.x_test == 8\n",
        "\n",
        "df_analysis = pd.DataFrame({\"Sentence\":sentences,\n",
        "                            'variables':sen_vars.sum(axis=1),\n",
        "                            \"and\":sen_and.sum(axis=1),\n",
        "                            \"or\":sen_or.sum(axis=1),\n",
        "                            \"not\":sen_not.sum(axis=1)})\n",
        "\n",
        "df_bad = df_analysis[np.array(index)]\n",
        "df_bad"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>variables</th>\n",
              "      <th>and</th>\n",
              "      <th>or</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>not not 5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>( ( 2 or 3 ) and not 2 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>( ( 3 or 2 ) and not 3 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Sentence  variables  and  or  not\n",
              "49                 not not 5          1    0   0    2\n",
              "72  ( ( 2 or 3 ) and not 2 )          3    1   1    1\n",
              "89  ( ( 3 or 2 ) and not 3 )          3    1   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "d_eG6CyByPn0",
        "outputId": "f1791fc7-cfde-4b4a-90e1-fc93c5865d34"
      },
      "source": [
        " same = []\n",
        " for i, r in df_analysis.drop(\"Sentence\", axis=1).iterrows():\n",
        "   for index, row in df_bad.drop(\"Sentence\", axis=1).drop_duplicates().iterrows():\n",
        "     if r.equals(row) and i not in df_bad.index:\n",
        "       same.append(i)\n",
        "\n",
        "df_analysis_correct = df_analysis.iloc[same]\n",
        "df_analysis_correct[\"True\"] = data.y_test[same].argmax(axis=1)\n",
        "df_analysis_correct[\"Predicted\"] = get_answer(pred[same]).argmax(axis=1)\n",
        "df_analysis_correct[\"Probability\"] = pred[same].max(axis=1)\n",
        "df_analysis_correct                      "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>variables</th>\n",
              "      <th>and</th>\n",
              "      <th>or</th>\n",
              "      <th>not</th>\n",
              "      <th>True</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>( not 5 and ( 2 or 5 ) )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>( not 5 and ( 4 or 5 ) )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.999977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>( ( 2 or 2 ) and not 1 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>( not 2 and ( 1 or 1 ) )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>( ( 3 or 3 ) and not 4 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>( ( 4 or 1 ) and not 1 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.990588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>( ( 3 or 1 ) and not 3 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.959426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>( not 3 and ( 3 or 2 ) )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>( ( 5 or 3 ) and not 5 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.998433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>not not 2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.464344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>( not 1 and ( 1 or 2 ) )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.818642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>( ( 2 or 1 ) and not 2 )</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.996603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Sentence  variables  and  or  not  True  Predicted  \\\n",
              "12   ( not 5 and ( 2 or 5 ) )          3    1   1    1     1          1   \n",
              "23   ( not 5 and ( 4 or 5 ) )          3    1   1    1     3          3   \n",
              "46   ( ( 2 or 2 ) and not 1 )          3    1   1    1     1          1   \n",
              "57   ( not 2 and ( 1 or 1 ) )          3    1   1    1     0          0   \n",
              "62   ( ( 3 or 3 ) and not 4 )          3    1   1    1     2          2   \n",
              "69   ( ( 4 or 1 ) and not 1 )          3    1   1    1     3          3   \n",
              "70   ( ( 3 or 1 ) and not 3 )          3    1   1    1     0          0   \n",
              "80   ( not 3 and ( 3 or 2 ) )          3    1   1    1     1          1   \n",
              "97   ( ( 5 or 3 ) and not 5 )          3    1   1    1     2          2   \n",
              "106                 not not 2          1    0   0    2     1          1   \n",
              "109  ( not 1 and ( 1 or 2 ) )          3    1   1    1     1          1   \n",
              "127  ( ( 2 or 1 ) and not 2 )          3    1   1    1     0          0   \n",
              "\n",
              "     Probability  \n",
              "12      0.999972  \n",
              "23      0.999977  \n",
              "46      0.999999  \n",
              "57      1.000000  \n",
              "62      1.000000  \n",
              "69      0.990588  \n",
              "70      0.959426  \n",
              "80      0.999807  \n",
              "97      0.998433  \n",
              "106     0.464344  \n",
              "109     0.818642  \n",
              "127     0.996603  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}