{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import functools\n",
    "from dataset.conclusion_generation import test_for_mental_models, generate_random_tree, generate_and_save_trees\n",
    "from dataset.logic_tree import OperatorNode\n",
    "from dataset.encoding import encode_mental_models_separated_sentences, load_sentences_and_conclusions\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.common import get_separated_sequences_mental_models_dataset\n",
    "import dataset.encoding\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.getcwd() + '\\\\temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 100 (0.2%) trees, correct: 87, recently correct: 87.0%, eta: 02s\n",
      "Checked 200 (0.4%) trees, correct: 172, recently correct: 85.0%, eta: 04s\n",
      "Checked 300 (0.6%) trees, correct: 247, recently correct: 75.0%, eta: 03s\n",
      "Checked 400 (0.8%) trees, correct: 333, recently correct: 86.0%, eta: 03s\n",
      "Checked 500 (1.0%) trees, correct: 398, recently correct: 65.0%, eta: 03s\n",
      "Checked 600 (1.2%) trees, correct: 462, recently correct: 64.0%, eta: 03s\n",
      "Checked 700 (1.4%) trees, correct: 515, recently correct: 53.0%, eta: 03s\n",
      "Checked 800 (1.6%) trees, correct: 581, recently correct: 66.0%, eta: 03s\n",
      "Checked 900 (1.8%) trees, correct: 643, recently correct: 62.0%, eta: 03s\n",
      "Checked 1000 (2.0%) trees, correct: 703, recently correct: 60.0%, eta: 03s\n",
      "Checked 1100 (2.2%) trees, correct: 759, recently correct: 56.0%, eta: 03s\n",
      "Checked 1200 (2.4%) trees, correct: 811, recently correct: 52.0%, eta: 03s\n",
      "Checked 1300 (2.6%) trees, correct: 867, recently correct: 56.0%, eta: 03s\n",
      "Checked 1400 (2.8%) trees, correct: 920, recently correct: 53.0%, eta: 03s\n",
      "Checked 1500 (3.0%) trees, correct: 971, recently correct: 51.0%, eta: 03s\n",
      "Checked 1600 (3.2%) trees, correct: 1016, recently correct: 45.0%, eta: 03s\n",
      "Checked 1700 (3.4%) trees, correct: 1068, recently correct: 52.0%, eta: 03s\n",
      "Checked 1800 (3.6%) trees, correct: 1115, recently correct: 47.0%, eta: 03s\n",
      "Checked 1900 (3.8%) trees, correct: 1160, recently correct: 45.0%, eta: 03s\n",
      "Checked 2000 (4.0%) trees, correct: 1201, recently correct: 41.0%, eta: 03s\n",
      "Checked 2100 (4.2%) trees, correct: 1237, recently correct: 36.0%, eta: 03s\n",
      "Checked 2200 (4.4%) trees, correct: 1282, recently correct: 45.0%, eta: 03s\n",
      "Checked 2300 (4.6%) trees, correct: 1322, recently correct: 40.0%, eta: 03s\n",
      "Checked 2400 (4.8%) trees, correct: 1366, recently correct: 44.0%, eta: 03s\n",
      "Checked 2500 (5.0%) trees, correct: 1391, recently correct: 25.0%, eta: 03s\n",
      "Checked 2600 (5.2%) trees, correct: 1431, recently correct: 40.0%, eta: 03s\n",
      "Checked 2700 (5.4%) trees, correct: 1464, recently correct: 33.0%, eta: 03s\n",
      "Checked 2800 (5.6%) trees, correct: 1498, recently correct: 34.0%, eta: 03s\n",
      "Checked 2900 (5.8%) trees, correct: 1529, recently correct: 31.0%, eta: 03s\n",
      "Checked 3000 (6.0%) trees, correct: 1566, recently correct: 37.0%, eta: 03s\n",
      "Checked 3100 (6.2%) trees, correct: 1608, recently correct: 42.0%, eta: 03s\n",
      "Checked 3200 (6.4%) trees, correct: 1642, recently correct: 34.0%, eta: 03s\n",
      "Checked 3300 (6.6%) trees, correct: 1677, recently correct: 35.0%, eta: 03s\n",
      "Checked 3400 (6.8%) trees, correct: 1716, recently correct: 39.0%, eta: 03s\n",
      "Checked 3500 (7.0%) trees, correct: 1749, recently correct: 33.0%, eta: 03s\n",
      "Checked 3600 (7.2%) trees, correct: 1777, recently correct: 28.0%, eta: 03s\n",
      "Checked 3700 (7.4%) trees, correct: 1801, recently correct: 24.0%, eta: 03s\n",
      "Checked 3800 (7.6%) trees, correct: 1832, recently correct: 31.0%, eta: 03s\n",
      "Checked 3900 (7.8%) trees, correct: 1863, recently correct: 31.0%, eta: 03s\n",
      "Checked 4000 (8.0%) trees, correct: 1891, recently correct: 28.0%, eta: 03s\n",
      "Checked 4100 (8.2%) trees, correct: 1922, recently correct: 31.0%, eta: 03s\n",
      "Checked 4200 (8.4%) trees, correct: 1948, recently correct: 26.0%, eta: 03s\n",
      "Checked 4300 (8.6%) trees, correct: 1970, recently correct: 22.0%, eta: 03s\n",
      "Checked 4400 (8.8%) trees, correct: 1994, recently correct: 24.0%, eta: 03s\n",
      "Checked 4500 (9.0%) trees, correct: 2015, recently correct: 21.0%, eta: 03s\n",
      "Checked 4600 (9.2%) trees, correct: 2034, recently correct: 19.0%, eta: 03s\n",
      "Checked 4700 (9.4%) trees, correct: 2057, recently correct: 23.0%, eta: 03s\n",
      "Checked 4800 (9.6%) trees, correct: 2084, recently correct: 27.0%, eta: 03s\n",
      "Checked 4900 (9.8%) trees, correct: 2107, recently correct: 23.0%, eta: 03s\n",
      "Checked 5000 (10.0%) trees, correct: 2130, recently correct: 23.0%, eta: 03s\n",
      "Checked 5100 (10.2%) trees, correct: 2155, recently correct: 25.0%, eta: 03s\n",
      "Checked 5200 (10.4%) trees, correct: 2183, recently correct: 28.0%, eta: 03s\n",
      "Checked 5300 (10.6%) trees, correct: 2198, recently correct: 15.0%, eta: 03s\n",
      "Checked 5400 (10.8%) trees, correct: 2218, recently correct: 20.0%, eta: 03s\n",
      "Checked 5500 (11.0%) trees, correct: 2237, recently correct: 19.0%, eta: 03s\n",
      "Checked 5600 (11.2%) trees, correct: 2256, recently correct: 19.0%, eta: 03s\n",
      "Checked 5700 (11.4%) trees, correct: 2277, recently correct: 21.0%, eta: 03s\n",
      "Checked 5800 (11.6%) trees, correct: 2295, recently correct: 18.0%, eta: 03s\n",
      "Checked 5900 (11.8%) trees, correct: 2311, recently correct: 16.0%, eta: 03s\n",
      "Checked 6000 (12.0%) trees, correct: 2333, recently correct: 22.0%, eta: 03s\n",
      "Checked 6100 (12.2%) trees, correct: 2351, recently correct: 18.0%, eta: 03s\n",
      "Checked 6200 (12.4%) trees, correct: 2371, recently correct: 20.0%, eta: 03s\n",
      "Checked 6300 (12.6%) trees, correct: 2389, recently correct: 18.0%, eta: 03s\n",
      "Checked 6400 (12.8%) trees, correct: 2402, recently correct: 13.0%, eta: 03s\n",
      "Checked 6500 (13.0%) trees, correct: 2421, recently correct: 19.0%, eta: 03s\n",
      "Checked 6600 (13.2%) trees, correct: 2428, recently correct: 7.0%, eta: 03s\n",
      "Checked 6700 (13.4%) trees, correct: 2445, recently correct: 17.0%, eta: 03s\n",
      "Checked 6800 (13.6%) trees, correct: 2469, recently correct: 24.0%, eta: 03s\n",
      "Checked 6900 (13.8%) trees, correct: 2481, recently correct: 12.0%, eta: 03s\n",
      "Checked 7000 (14.0%) trees, correct: 2496, recently correct: 15.0%, eta: 03s\n",
      "Checked 7100 (14.2%) trees, correct: 2511, recently correct: 15.0%, eta: 03s\n",
      "Checked 7200 (14.4%) trees, correct: 2532, recently correct: 21.0%, eta: 03s\n",
      "Checked 7300 (14.6%) trees, correct: 2548, recently correct: 16.0%, eta: 03s\n",
      "Checked 7400 (14.8%) trees, correct: 2564, recently correct: 16.0%, eta: 03s\n",
      "Checked 7500 (15.0%) trees, correct: 2583, recently correct: 19.0%, eta: 03s\n",
      "Checked 7600 (15.2%) trees, correct: 2595, recently correct: 12.0%, eta: 03s\n",
      "Checked 7700 (15.4%) trees, correct: 2615, recently correct: 20.0%, eta: 03s\n",
      "Checked 7800 (15.6%) trees, correct: 2624, recently correct: 9.0%, eta: 03s\n",
      "Checked 7900 (15.8%) trees, correct: 2639, recently correct: 15.0%, eta: 03s\n",
      "Checked 8000 (16.0%) trees, correct: 2652, recently correct: 13.0%, eta: 03s\n",
      "Checked 8100 (16.2%) trees, correct: 2662, recently correct: 10.0%, eta: 03s\n",
      "Checked 8200 (16.4%) trees, correct: 2678, recently correct: 16.0%, eta: 03s\n",
      "Checked 8300 (16.6%) trees, correct: 2689, recently correct: 11.0%, eta: 03s\n",
      "Checked 8400 (16.8%) trees, correct: 2702, recently correct: 13.0%, eta: 03s\n",
      "Checked 8500 (17.0%) trees, correct: 2715, recently correct: 13.0%, eta: 03s\n",
      "Checked 8600 (17.2%) trees, correct: 2726, recently correct: 11.0%, eta: 03s\n",
      "Checked 8700 (17.4%) trees, correct: 2732, recently correct: 6.0%, eta: 03s\n",
      "Checked 8800 (17.6%) trees, correct: 2742, recently correct: 10.0%, eta: 03s\n",
      "Checked 8900 (17.8%) trees, correct: 2753, recently correct: 11.0%, eta: 03s\n",
      "Checked 9000 (18.0%) trees, correct: 2763, recently correct: 10.0%, eta: 03s\n",
      "Checked 9100 (18.2%) trees, correct: 2777, recently correct: 14.0%, eta: 03s\n",
      "Checked 9200 (18.4%) trees, correct: 2785, recently correct: 8.0%, eta: 03s\n",
      "Checked 9300 (18.6%) trees, correct: 2800, recently correct: 15.0%, eta: 03s\n",
      "Checked 9400 (18.8%) trees, correct: 2811, recently correct: 11.0%, eta: 03s\n",
      "Checked 9500 (19.0%) trees, correct: 2820, recently correct: 9.0%, eta: 03s\n",
      "Checked 9600 (19.2%) trees, correct: 2833, recently correct: 13.0%, eta: 03s\n",
      "Checked 9700 (19.4%) trees, correct: 2840, recently correct: 7.0%, eta: 03s\n",
      "Checked 9800 (19.6%) trees, correct: 2852, recently correct: 12.0%, eta: 03s\n",
      "Checked 9900 (19.8%) trees, correct: 2862, recently correct: 10.0%, eta: 03s\n",
      "Checked 10000 (20.0%) trees, correct: 2868, recently correct: 6.0%, eta: 03s\n",
      "Checked 10100 (20.2%) trees, correct: 2877, recently correct: 9.0%, eta: 03s\n",
      "Checked 10200 (20.4%) trees, correct: 2891, recently correct: 14.0%, eta: 03s\n",
      "Checked 10300 (20.6%) trees, correct: 2900, recently correct: 9.0%, eta: 03s\n",
      "Checked 10400 (20.8%) trees, correct: 2909, recently correct: 9.0%, eta: 03s\n",
      "Checked 10500 (21.0%) trees, correct: 2919, recently correct: 10.0%, eta: 03s\n",
      "Checked 10600 (21.2%) trees, correct: 2931, recently correct: 12.0%, eta: 03s\n",
      "Checked 10700 (21.4%) trees, correct: 2937, recently correct: 6.0%, eta: 03s\n",
      "Checked 10800 (21.6%) trees, correct: 2945, recently correct: 8.0%, eta: 03s\n",
      "Checked 10900 (21.8%) trees, correct: 2952, recently correct: 7.0%, eta: 03s\n",
      "Checked 11000 (22.0%) trees, correct: 2956, recently correct: 4.0%, eta: 03s\n",
      "Checked 11100 (22.2%) trees, correct: 2967, recently correct: 11.0%, eta: 03s\n",
      "Checked 11200 (22.4%) trees, correct: 2976, recently correct: 9.0%, eta: 03s\n",
      "Checked 11300 (22.6%) trees, correct: 2983, recently correct: 7.0%, eta: 03s\n",
      "Checked 11400 (22.8%) trees, correct: 2986, recently correct: 3.0%, eta: 03s\n",
      "Checked 11500 (23.0%) trees, correct: 2995, recently correct: 9.0%, eta: 03s\n",
      "Checked 11600 (23.2%) trees, correct: 3001, recently correct: 6.0%, eta: 03s\n",
      "Checked 11700 (23.4%) trees, correct: 3008, recently correct: 7.0%, eta: 03s\n",
      "Checked 11800 (23.6%) trees, correct: 3016, recently correct: 8.0%, eta: 03s\n",
      "Checked 11900 (23.8%) trees, correct: 3026, recently correct: 10.0%, eta: 03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 12000 (24.0%) trees, correct: 3037, recently correct: 11.0%, eta: 03s\n",
      "Checked 12100 (24.2%) trees, correct: 3039, recently correct: 2.0%, eta: 03s\n",
      "Checked 12200 (24.4%) trees, correct: 3045, recently correct: 6.0%, eta: 03s\n",
      "Checked 12300 (24.6%) trees, correct: 3052, recently correct: 7.0%, eta: 03s\n",
      "Checked 12400 (24.8%) trees, correct: 3058, recently correct: 6.0%, eta: 03s\n",
      "Checked 12500 (25.0%) trees, correct: 3062, recently correct: 4.0%, eta: 03s\n",
      "Checked 12600 (25.2%) trees, correct: 3071, recently correct: 9.0%, eta: 03s\n",
      "Checked 12700 (25.4%) trees, correct: 3076, recently correct: 5.0%, eta: 03s\n",
      "Checked 12800 (25.6%) trees, correct: 3082, recently correct: 6.0%, eta: 03s\n",
      "Checked 12900 (25.8%) trees, correct: 3088, recently correct: 6.0%, eta: 03s\n",
      "Checked 13000 (26.0%) trees, correct: 3091, recently correct: 3.0%, eta: 03s\n",
      "Checked 13100 (26.2%) trees, correct: 3093, recently correct: 2.0%, eta: 03s\n",
      "Checked 13200 (26.4%) trees, correct: 3096, recently correct: 3.0%, eta: 03s\n",
      "Checked 13300 (26.6%) trees, correct: 3100, recently correct: 4.0%, eta: 03s\n",
      "Checked 13400 (26.8%) trees, correct: 3104, recently correct: 4.0%, eta: 03s\n",
      "Checked 13500 (27.0%) trees, correct: 3110, recently correct: 6.0%, eta: 03s\n",
      "Checked 13600 (27.2%) trees, correct: 3113, recently correct: 3.0%, eta: 03s\n",
      "Checked 13700 (27.4%) trees, correct: 3120, recently correct: 7.0%, eta: 03s\n",
      "Checked 13800 (27.6%) trees, correct: 3126, recently correct: 6.0%, eta: 03s\n",
      "Checked 13900 (27.8%) trees, correct: 3131, recently correct: 5.0%, eta: 03s\n",
      "Checked 14000 (28.0%) trees, correct: 3138, recently correct: 7.0%, eta: 03s\n",
      "Checked 14100 (28.2%) trees, correct: 3145, recently correct: 7.0%, eta: 03s\n",
      "Checked 14200 (28.4%) trees, correct: 3149, recently correct: 4.0%, eta: 03s\n",
      "Checked 14300 (28.6%) trees, correct: 3156, recently correct: 7.0%, eta: 03s\n",
      "Checked 14400 (28.8%) trees, correct: 3163, recently correct: 7.0%, eta: 03s\n",
      "Checked 14500 (29.0%) trees, correct: 3163, recently correct: 0.0%, eta: 03s\n",
      "Checked 14600 (29.2%) trees, correct: 3165, recently correct: 2.0%, eta: 03s\n",
      "Checked 14700 (29.4%) trees, correct: 3169, recently correct: 4.0%, eta: 03s\n",
      "Checked 14800 (29.6%) trees, correct: 3177, recently correct: 8.0%, eta: 03s\n",
      "Checked 14900 (29.8%) trees, correct: 3180, recently correct: 3.0%, eta: 03s\n",
      "Checked 15000 (30.0%) trees, correct: 3184, recently correct: 4.0%, eta: 02s\n",
      "Checked 15100 (30.2%) trees, correct: 3190, recently correct: 6.0%, eta: 02s\n",
      "Checked 15200 (30.4%) trees, correct: 3195, recently correct: 5.0%, eta: 02s\n",
      "Checked 15300 (30.6%) trees, correct: 3197, recently correct: 2.0%, eta: 02s\n",
      "Checked 15400 (30.8%) trees, correct: 3200, recently correct: 3.0%, eta: 02s\n",
      "Checked 15500 (31.0%) trees, correct: 3204, recently correct: 4.0%, eta: 02s\n",
      "Checked 15600 (31.2%) trees, correct: 3208, recently correct: 4.0%, eta: 02s\n",
      "Checked 15700 (31.4%) trees, correct: 3212, recently correct: 4.0%, eta: 02s\n",
      "Checked 15800 (31.6%) trees, correct: 3219, recently correct: 7.0%, eta: 02s\n",
      "Checked 15900 (31.8%) trees, correct: 3222, recently correct: 3.0%, eta: 02s\n",
      "Checked 16000 (32.0%) trees, correct: 3226, recently correct: 4.0%, eta: 02s\n",
      "Checked 16100 (32.2%) trees, correct: 3232, recently correct: 6.0%, eta: 02s\n",
      "Checked 16200 (32.4%) trees, correct: 3234, recently correct: 2.0%, eta: 02s\n",
      "Checked 16300 (32.6%) trees, correct: 3238, recently correct: 4.0%, eta: 02s\n",
      "Checked 16400 (32.8%) trees, correct: 3246, recently correct: 8.0%, eta: 02s\n",
      "Checked 16500 (33.0%) trees, correct: 3253, recently correct: 7.0%, eta: 02s\n",
      "Checked 16600 (33.2%) trees, correct: 3255, recently correct: 2.0%, eta: 02s\n",
      "Checked 16700 (33.4%) trees, correct: 3260, recently correct: 5.0%, eta: 02s\n",
      "Checked 16800 (33.6%) trees, correct: 3263, recently correct: 3.0%, eta: 02s\n",
      "Checked 16900 (33.8%) trees, correct: 3263, recently correct: 0.0%, eta: 02s\n",
      "Checked 17000 (34.0%) trees, correct: 3269, recently correct: 6.0%, eta: 02s\n",
      "Checked 17100 (34.2%) trees, correct: 3270, recently correct: 1.0%, eta: 02s\n",
      "Checked 17200 (34.4%) trees, correct: 3274, recently correct: 4.0%, eta: 02s\n",
      "Checked 17300 (34.6%) trees, correct: 3278, recently correct: 4.0%, eta: 02s\n",
      "Checked 17400 (34.8%) trees, correct: 3282, recently correct: 4.0%, eta: 02s\n",
      "Checked 17500 (35.0%) trees, correct: 3283, recently correct: 1.0%, eta: 02s\n",
      "Checked 17600 (35.2%) trees, correct: 3284, recently correct: 1.0%, eta: 02s\n",
      "Checked 17700 (35.4%) trees, correct: 3291, recently correct: 7.0%, eta: 02s\n",
      "Checked 17800 (35.6%) trees, correct: 3296, recently correct: 5.0%, eta: 02s\n",
      "Checked 17900 (35.8%) trees, correct: 3298, recently correct: 2.0%, eta: 02s\n",
      "Checked 18000 (36.0%) trees, correct: 3305, recently correct: 7.0%, eta: 02s\n",
      "Checked 18100 (36.2%) trees, correct: 3307, recently correct: 2.0%, eta: 02s\n",
      "Checked 18200 (36.4%) trees, correct: 3313, recently correct: 6.0%, eta: 02s\n",
      "Checked 18300 (36.6%) trees, correct: 3316, recently correct: 3.0%, eta: 02s\n",
      "Checked 18400 (36.8%) trees, correct: 3320, recently correct: 4.0%, eta: 02s\n",
      "Checked 18500 (37.0%) trees, correct: 3324, recently correct: 4.0%, eta: 02s\n",
      "Checked 18600 (37.2%) trees, correct: 3328, recently correct: 4.0%, eta: 02s\n",
      "Checked 18700 (37.4%) trees, correct: 3330, recently correct: 2.0%, eta: 02s\n",
      "Checked 18800 (37.6%) trees, correct: 3331, recently correct: 1.0%, eta: 02s\n",
      "Checked 18900 (37.8%) trees, correct: 3332, recently correct: 1.0%, eta: 02s\n",
      "Checked 19000 (38.0%) trees, correct: 3334, recently correct: 2.0%, eta: 02s\n",
      "Checked 19100 (38.2%) trees, correct: 3337, recently correct: 3.0%, eta: 02s\n",
      "Checked 19200 (38.4%) trees, correct: 3339, recently correct: 2.0%, eta: 02s\n",
      "Checked 19300 (38.6%) trees, correct: 3345, recently correct: 6.0%, eta: 02s\n",
      "Checked 19400 (38.8%) trees, correct: 3346, recently correct: 1.0%, eta: 02s\n",
      "Checked 19500 (39.0%) trees, correct: 3350, recently correct: 4.0%, eta: 02s\n",
      "Checked 19600 (39.2%) trees, correct: 3352, recently correct: 2.0%, eta: 02s\n",
      "Checked 19700 (39.4%) trees, correct: 3354, recently correct: 2.0%, eta: 02s\n",
      "Checked 19800 (39.6%) trees, correct: 3355, recently correct: 1.0%, eta: 02s\n",
      "Checked 19900 (39.8%) trees, correct: 3359, recently correct: 4.0%, eta: 02s\n",
      "Checked 20000 (40.0%) trees, correct: 3361, recently correct: 2.0%, eta: 02s\n",
      "Checked 20100 (40.2%) trees, correct: 3364, recently correct: 3.0%, eta: 02s\n",
      "Checked 20200 (40.4%) trees, correct: 3365, recently correct: 1.0%, eta: 02s\n",
      "Checked 20300 (40.6%) trees, correct: 3368, recently correct: 3.0%, eta: 02s\n",
      "Checked 20400 (40.8%) trees, correct: 3368, recently correct: 0.0%, eta: 02s\n",
      "Checked 20500 (41.0%) trees, correct: 3369, recently correct: 1.0%, eta: 02s\n",
      "Checked 20600 (41.2%) trees, correct: 3372, recently correct: 3.0%, eta: 02s\n",
      "Checked 20700 (41.4%) trees, correct: 3375, recently correct: 3.0%, eta: 02s\n",
      "Checked 20800 (41.6%) trees, correct: 3376, recently correct: 1.0%, eta: 02s\n",
      "Checked 20900 (41.8%) trees, correct: 3379, recently correct: 3.0%, eta: 02s\n",
      "Checked 21000 (42.0%) trees, correct: 3380, recently correct: 1.0%, eta: 02s\n",
      "Checked 21100 (42.2%) trees, correct: 3381, recently correct: 1.0%, eta: 02s\n",
      "Checked 21200 (42.4%) trees, correct: 3382, recently correct: 1.0%, eta: 02s\n",
      "Checked 21300 (42.6%) trees, correct: 3383, recently correct: 1.0%, eta: 02s\n",
      "Checked 21400 (42.8%) trees, correct: 3385, recently correct: 2.0%, eta: 02s\n",
      "Checked 21500 (43.0%) trees, correct: 3387, recently correct: 2.0%, eta: 02s\n",
      "Checked 21600 (43.2%) trees, correct: 3391, recently correct: 4.0%, eta: 02s\n",
      "Checked 21700 (43.4%) trees, correct: 3395, recently correct: 4.0%, eta: 02s\n",
      "Checked 21800 (43.6%) trees, correct: 3398, recently correct: 3.0%, eta: 02s\n",
      "Checked 21900 (43.8%) trees, correct: 3399, recently correct: 1.0%, eta: 02s\n",
      "Checked 22000 (44.0%) trees, correct: 3399, recently correct: 0.0%, eta: 02s\n",
      "Checked 22100 (44.2%) trees, correct: 3400, recently correct: 1.0%, eta: 02s\n",
      "Checked 22200 (44.4%) trees, correct: 3402, recently correct: 2.0%, eta: 02s\n",
      "Checked 22300 (44.6%) trees, correct: 3405, recently correct: 3.0%, eta: 02s\n",
      "Checked 22400 (44.8%) trees, correct: 3406, recently correct: 1.0%, eta: 02s\n",
      "Checked 22500 (45.0%) trees, correct: 3407, recently correct: 1.0%, eta: 02s\n",
      "Checked 22600 (45.2%) trees, correct: 3408, recently correct: 1.0%, eta: 02s\n",
      "Checked 22700 (45.4%) trees, correct: 3409, recently correct: 1.0%, eta: 02s\n",
      "Checked 22800 (45.6%) trees, correct: 3413, recently correct: 4.0%, eta: 02s\n",
      "Checked 22900 (45.8%) trees, correct: 3415, recently correct: 2.0%, eta: 02s\n",
      "Checked 23000 (46.0%) trees, correct: 3415, recently correct: 0.0%, eta: 02s\n",
      "Checked 23100 (46.2%) trees, correct: 3415, recently correct: 0.0%, eta: 02s\n",
      "Checked 23200 (46.4%) trees, correct: 3415, recently correct: 0.0%, eta: 02s\n",
      "Checked 23300 (46.6%) trees, correct: 3415, recently correct: 0.0%, eta: 02s\n",
      "Checked 23400 (46.8%) trees, correct: 3415, recently correct: 0.0%, eta: 02s\n",
      "Checked 23500 (47.0%) trees, correct: 3417, recently correct: 2.0%, eta: 02s\n",
      "Checked 23600 (47.2%) trees, correct: 3418, recently correct: 1.0%, eta: 02s\n",
      "Checked 23700 (47.4%) trees, correct: 3419, recently correct: 1.0%, eta: 02s\n",
      "Checked 23800 (47.6%) trees, correct: 3419, recently correct: 0.0%, eta: 02s\n",
      "Checked 23900 (47.8%) trees, correct: 3419, recently correct: 0.0%, eta: 02s\n",
      "Checked 24000 (48.0%) trees, correct: 3420, recently correct: 1.0%, eta: 02s\n",
      "Checked 24100 (48.2%) trees, correct: 3420, recently correct: 0.0%, eta: 02s\n",
      "Checked 24200 (48.4%) trees, correct: 3421, recently correct: 1.0%, eta: 02s\n",
      "Checked 24300 (48.6%) trees, correct: 3421, recently correct: 0.0%, eta: 02s\n",
      "Checked 24400 (48.8%) trees, correct: 3421, recently correct: 0.0%, eta: 02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 24500 (49.0%) trees, correct: 3422, recently correct: 1.0%, eta: 02s\n",
      "Checked 24600 (49.2%) trees, correct: 3422, recently correct: 0.0%, eta: 02s\n",
      "Checked 24700 (49.4%) trees, correct: 3424, recently correct: 2.0%, eta: 02s\n",
      "Checked 24800 (49.6%) trees, correct: 3425, recently correct: 1.0%, eta: 02s\n",
      "Checked 24900 (49.8%) trees, correct: 3425, recently correct: 0.0%, eta: 02s\n",
      "Checked 25000 (50.0%) trees, correct: 3426, recently correct: 1.0%, eta: 02s\n",
      "Checked 25100 (50.2%) trees, correct: 3427, recently correct: 1.0%, eta: 02s\n",
      "Checked 25200 (50.4%) trees, correct: 3427, recently correct: 0.0%, eta: 02s\n",
      "Checked 25300 (50.6%) trees, correct: 3427, recently correct: 0.0%, eta: 02s\n",
      "Checked 25400 (50.8%) trees, correct: 3429, recently correct: 2.0%, eta: 02s\n",
      "Checked 25500 (51.0%) trees, correct: 3430, recently correct: 1.0%, eta: 02s\n",
      "Checked 25600 (51.2%) trees, correct: 3430, recently correct: 0.0%, eta: 02s\n",
      "Checked 25700 (51.4%) trees, correct: 3433, recently correct: 3.0%, eta: 02s\n",
      "Checked 25800 (51.6%) trees, correct: 3435, recently correct: 2.0%, eta: 02s\n",
      "Checked 25900 (51.8%) trees, correct: 3435, recently correct: 0.0%, eta: 02s\n",
      "Checked 26000 (52.0%) trees, correct: 3435, recently correct: 0.0%, eta: 02s\n",
      "Checked 26100 (52.2%) trees, correct: 3437, recently correct: 2.0%, eta: 02s\n",
      "Checked 26200 (52.4%) trees, correct: 3437, recently correct: 0.0%, eta: 02s\n",
      "Checked 26300 (52.6%) trees, correct: 3438, recently correct: 1.0%, eta: 02s\n",
      "Checked 26400 (52.8%) trees, correct: 3438, recently correct: 0.0%, eta: 02s\n",
      "Checked 26500 (53.0%) trees, correct: 3439, recently correct: 1.0%, eta: 02s\n",
      "Checked 26600 (53.2%) trees, correct: 3440, recently correct: 1.0%, eta: 02s\n",
      "Checked 26700 (53.4%) trees, correct: 3444, recently correct: 4.0%, eta: 02s\n",
      "Checked 26800 (53.6%) trees, correct: 3444, recently correct: 0.0%, eta: 01s\n",
      "Checked 26900 (53.8%) trees, correct: 3444, recently correct: 0.0%, eta: 01s\n",
      "Checked 27000 (54.0%) trees, correct: 3444, recently correct: 0.0%, eta: 01s\n",
      "Checked 27100 (54.2%) trees, correct: 3445, recently correct: 1.0%, eta: 01s\n",
      "Checked 27200 (54.4%) trees, correct: 3445, recently correct: 0.0%, eta: 01s\n",
      "Checked 27300 (54.6%) trees, correct: 3445, recently correct: 0.0%, eta: 01s\n",
      "Checked 27400 (54.8%) trees, correct: 3448, recently correct: 3.0%, eta: 01s\n",
      "Checked 27500 (55.0%) trees, correct: 3449, recently correct: 1.0%, eta: 01s\n",
      "Checked 27600 (55.2%) trees, correct: 3449, recently correct: 0.0%, eta: 01s\n",
      "Checked 27700 (55.4%) trees, correct: 3449, recently correct: 0.0%, eta: 01s\n",
      "Checked 27800 (55.6%) trees, correct: 3451, recently correct: 2.0%, eta: 01s\n",
      "Checked 27900 (55.8%) trees, correct: 3451, recently correct: 0.0%, eta: 01s\n",
      "Checked 28000 (56.0%) trees, correct: 3454, recently correct: 3.0%, eta: 01s\n",
      "Checked 28100 (56.2%) trees, correct: 3456, recently correct: 2.0%, eta: 01s\n",
      "Checked 28200 (56.4%) trees, correct: 3458, recently correct: 2.0%, eta: 01s\n",
      "Checked 28300 (56.6%) trees, correct: 3458, recently correct: 0.0%, eta: 01s\n",
      "Checked 28400 (56.8%) trees, correct: 3458, recently correct: 0.0%, eta: 01s\n",
      "Checked 28500 (57.0%) trees, correct: 3458, recently correct: 0.0%, eta: 01s\n",
      "Checked 28600 (57.2%) trees, correct: 3459, recently correct: 1.0%, eta: 01s\n",
      "Checked 28700 (57.4%) trees, correct: 3460, recently correct: 1.0%, eta: 01s\n",
      "Checked 28800 (57.6%) trees, correct: 3460, recently correct: 0.0%, eta: 01s\n",
      "Checked 28900 (57.8%) trees, correct: 3460, recently correct: 0.0%, eta: 01s\n",
      "Checked 29000 (58.0%) trees, correct: 3461, recently correct: 1.0%, eta: 01s\n",
      "Checked 29100 (58.2%) trees, correct: 3462, recently correct: 1.0%, eta: 01s\n",
      "Checked 29200 (58.4%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29300 (58.6%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29400 (58.8%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29500 (59.0%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29600 (59.2%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29700 (59.4%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29800 (59.6%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 29900 (59.8%) trees, correct: 3462, recently correct: 0.0%, eta: 01s\n",
      "Checked 30000 (60.0%) trees, correct: 3463, recently correct: 1.0%, eta: 01s\n",
      "Checked 30100 (60.2%) trees, correct: 3464, recently correct: 1.0%, eta: 01s\n",
      "Checked 30200 (60.4%) trees, correct: 3464, recently correct: 0.0%, eta: 01s\n",
      "Checked 30300 (60.6%) trees, correct: 3464, recently correct: 0.0%, eta: 01s\n",
      "Checked 30400 (60.8%) trees, correct: 3464, recently correct: 0.0%, eta: 01s\n",
      "Checked 30500 (61.0%) trees, correct: 3464, recently correct: 0.0%, eta: 01s\n",
      "Checked 30600 (61.2%) trees, correct: 3465, recently correct: 1.0%, eta: 01s\n",
      "Checked 30700 (61.4%) trees, correct: 3465, recently correct: 0.0%, eta: 01s\n",
      "Checked 30800 (61.6%) trees, correct: 3465, recently correct: 0.0%, eta: 01s\n",
      "Checked 30900 (61.8%) trees, correct: 3466, recently correct: 1.0%, eta: 01s\n",
      "Checked 31000 (62.0%) trees, correct: 3466, recently correct: 0.0%, eta: 01s\n",
      "Checked 31100 (62.2%) trees, correct: 3466, recently correct: 0.0%, eta: 01s\n",
      "Checked 31200 (62.4%) trees, correct: 3466, recently correct: 0.0%, eta: 01s\n",
      "Checked 31300 (62.6%) trees, correct: 3466, recently correct: 0.0%, eta: 01s\n",
      "Checked 31400 (62.8%) trees, correct: 3467, recently correct: 1.0%, eta: 01s\n",
      "Checked 31500 (63.0%) trees, correct: 3467, recently correct: 0.0%, eta: 01s\n",
      "Checked 31600 (63.2%) trees, correct: 3468, recently correct: 1.0%, eta: 01s\n",
      "Checked 31700 (63.4%) trees, correct: 3468, recently correct: 0.0%, eta: 01s\n",
      "Checked 31800 (63.6%) trees, correct: 3468, recently correct: 0.0%, eta: 01s\n",
      "Checked 31900 (63.8%) trees, correct: 3468, recently correct: 0.0%, eta: 01s\n",
      "Checked 32000 (64.0%) trees, correct: 3469, recently correct: 1.0%, eta: 01s\n",
      "Checked 32100 (64.2%) trees, correct: 3469, recently correct: 0.0%, eta: 01s\n",
      "Checked 32200 (64.4%) trees, correct: 3469, recently correct: 0.0%, eta: 01s\n",
      "Checked 32300 (64.6%) trees, correct: 3469, recently correct: 0.0%, eta: 01s\n",
      "Checked 32400 (64.8%) trees, correct: 3469, recently correct: 0.0%, eta: 01s\n",
      "Checked 32500 (65.0%) trees, correct: 3469, recently correct: 0.0%, eta: 01s\n",
      "Checked 32600 (65.2%) trees, correct: 3470, recently correct: 1.0%, eta: 01s\n",
      "Checked 32700 (65.4%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 32800 (65.6%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 32900 (65.8%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33000 (66.0%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33100 (66.2%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33200 (66.4%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33300 (66.6%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33400 (66.8%) trees, correct: 3470, recently correct: 0.0%, eta: 01s\n",
      "Checked 33500 (67.0%) trees, correct: 3471, recently correct: 1.0%, eta: 01s\n",
      "Checked 33600 (67.2%) trees, correct: 3471, recently correct: 0.0%, eta: 01s\n",
      "Checked 33700 (67.4%) trees, correct: 3472, recently correct: 1.0%, eta: 01s\n",
      "Checked 33800 (67.6%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 33900 (67.8%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34000 (68.0%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34100 (68.2%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34200 (68.4%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34300 (68.6%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34400 (68.8%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34500 (69.0%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34600 (69.2%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34700 (69.4%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34800 (69.6%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 34900 (69.8%) trees, correct: 3472, recently correct: 0.0%, eta: 01s\n",
      "Checked 35000 (70.0%) trees, correct: 3473, recently correct: 1.0%, eta: 01s\n",
      "Checked 35100 (70.2%) trees, correct: 3473, recently correct: 0.0%, eta: 01s\n",
      "Checked 35200 (70.4%) trees, correct: 3474, recently correct: 1.0%, eta: 01s\n",
      "Checked 35300 (70.6%) trees, correct: 3475, recently correct: 1.0%, eta: 01s\n",
      "Checked 35400 (70.8%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 35500 (71.0%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 35600 (71.2%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 35700 (71.4%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 35800 (71.6%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 35900 (71.8%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36000 (72.0%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36100 (72.2%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36200 (72.4%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36300 (72.6%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36400 (72.8%) trees, correct: 3475, recently correct: 0.0%, eta: 01s\n",
      "Checked 36500 (73.0%) trees, correct: 3476, recently correct: 1.0%, eta: 01s\n",
      "Checked 36600 (73.2%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 36700 (73.4%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 36800 (73.6%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 36900 (73.8%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 37000 (74.0%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 37100 (74.2%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 37200 (74.4%) trees, correct: 3476, recently correct: 0.0%, eta: 01s\n",
      "Checked 37300 (74.6%) trees, correct: 3477, recently correct: 1.0%, eta: 01s\n",
      "Checked 37400 (74.8%) trees, correct: 3477, recently correct: 0.0%, eta: 01s\n",
      "Checked 37500 (75.0%) trees, correct: 3477, recently correct: 0.0%, eta: 01s\n",
      "Checked 37600 (75.2%) trees, correct: 3477, recently correct: 0.0%, eta: 01s\n",
      "Checked 37700 (75.4%) trees, correct: 3477, recently correct: 0.0%, eta: 01s\n",
      "Checked 37800 (75.6%) trees, correct: 3478, recently correct: 1.0%, eta: 01s\n",
      "Checked 37900 (75.8%) trees, correct: 3479, recently correct: 1.0%, eta: 01s\n",
      "Checked 38000 (76.0%) trees, correct: 3479, recently correct: 0.0%, eta: 01s\n",
      "Checked 38100 (76.2%) trees, correct: 3479, recently correct: 0.0%, eta: 01s\n",
      "Checked 38200 (76.4%) trees, correct: 3480, recently correct: 1.0%, eta: 01s\n",
      "Checked 38300 (76.6%) trees, correct: 3480, recently correct: 0.0%, eta: 01s\n",
      "Checked 38400 (76.8%) trees, correct: 3480, recently correct: 0.0%, eta: 01s\n",
      "Checked 38500 (77.0%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 38600 (77.2%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 38700 (77.4%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 38800 (77.6%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 38900 (77.8%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 39000 (78.0%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 39100 (78.2%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 39200 (78.4%) trees, correct: 3480, recently correct: 0.0%, eta: 00s\n",
      "Checked 39300 (78.6%) trees, correct: 3481, recently correct: 1.0%, eta: 00s\n",
      "Checked 39400 (78.8%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 39500 (79.0%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 39600 (79.2%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 39700 (79.4%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 39800 (79.6%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 39900 (79.8%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40000 (80.0%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40100 (80.2%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40200 (80.4%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40300 (80.6%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40400 (80.8%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40500 (81.0%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40600 (81.2%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40700 (81.4%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40800 (81.6%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 40900 (81.8%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41000 (82.0%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41100 (82.2%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41200 (82.4%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41300 (82.6%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41400 (82.8%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41500 (83.0%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41600 (83.2%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41700 (83.4%) trees, correct: 3481, recently correct: 0.0%, eta: 00s\n",
      "Checked 41800 (83.6%) trees, correct: 3482, recently correct: 1.0%, eta: 00s\n",
      "Checked 41900 (83.8%) trees, correct: 3482, recently correct: 0.0%, eta: 00s\n",
      "Checked 42000 (84.0%) trees, correct: 3482, recently correct: 0.0%, eta: 00s\n",
      "Checked 42100 (84.2%) trees, correct: 3482, recently correct: 0.0%, eta: 00s\n",
      "Checked 42200 (84.4%) trees, correct: 3483, recently correct: 1.0%, eta: 00s\n",
      "Checked 42300 (84.6%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42400 (84.8%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42500 (85.0%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42600 (85.2%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42700 (85.4%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42800 (85.6%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 42900 (85.8%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 43000 (86.0%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 43100 (86.2%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 43200 (86.4%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 43300 (86.6%) trees, correct: 3483, recently correct: 0.0%, eta: 00s\n",
      "Checked 43400 (86.8%) trees, correct: 3484, recently correct: 1.0%, eta: 00s\n",
      "Checked 43500 (87.0%) trees, correct: 3484, recently correct: 0.0%, eta: 00s\n",
      "Checked 43600 (87.2%) trees, correct: 3485, recently correct: 1.0%, eta: 00s\n",
      "Checked 43700 (87.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 43800 (87.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 43900 (87.8%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44000 (88.0%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44100 (88.2%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44200 (88.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44300 (88.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44400 (88.8%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44500 (89.0%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44600 (89.2%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44700 (89.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44800 (89.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 44900 (89.8%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45000 (90.0%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45100 (90.2%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45200 (90.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45300 (90.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45400 (90.8%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45500 (91.0%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45600 (91.2%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45700 (91.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45800 (91.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 45900 (91.8%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 46000 (92.0%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 46100 (92.2%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 46200 (92.4%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 46300 (92.6%) trees, correct: 3485, recently correct: 0.0%, eta: 00s\n",
      "Checked 46400 (92.8%) trees, correct: 3486, recently correct: 1.0%, eta: 00s\n",
      "Checked 46500 (93.0%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 46600 (93.2%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 46700 (93.4%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 46800 (93.6%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 46900 (93.8%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 47000 (94.0%) trees, correct: 3486, recently correct: 0.0%, eta: 00s\n",
      "Checked 47100 (94.2%) trees, correct: 3487, recently correct: 1.0%, eta: 00s\n",
      "Checked 47200 (94.4%) trees, correct: 3487, recently correct: 0.0%, eta: 00s\n",
      "Checked 47300 (94.6%) trees, correct: 3487, recently correct: 0.0%, eta: 00s\n",
      "Checked 47400 (94.8%) trees, correct: 3487, recently correct: 0.0%, eta: 00s\n",
      "Checked 47500 (95.0%) trees, correct: 3487, recently correct: 0.0%, eta: 00s\n",
      "Checked 47600 (95.2%) trees, correct: 3488, recently correct: 1.0%, eta: 00s\n",
      "Checked 47700 (95.4%) trees, correct: 3488, recently correct: 0.0%, eta: 00s\n",
      "Checked 47800 (95.6%) trees, correct: 3488, recently correct: 0.0%, eta: 00s\n",
      "Checked 47900 (95.8%) trees, correct: 3488, recently correct: 0.0%, eta: 00s\n",
      "Checked 48000 (96.0%) trees, correct: 3489, recently correct: 1.0%, eta: 00s\n",
      "Checked 48100 (96.2%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48200 (96.4%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48300 (96.6%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48400 (96.8%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48500 (97.0%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48600 (97.2%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48700 (97.4%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 48800 (97.6%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 48900 (97.8%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49000 (98.0%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49100 (98.2%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49200 (98.4%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49300 (98.6%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49400 (98.8%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49500 (99.0%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49600 (99.2%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49700 (99.4%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49800 (99.6%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 49900 (99.8%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "Checked 50000 (100.0%) trees, correct: 3489, recently correct: 0.0%, eta: 00s\n",
      "found trees: 3489\n",
      "infix tree: ( 5 or 1 ) sep not 1\n",
      "prefix tree: sep or 5 1 not 1\n",
      "conclusion: FnnnT\n",
      "\n",
      "infix tree: ( 4 or 3 ) sep ( 5 and 4 )\n",
      "prefix tree: sep or 4 3 and 5 4\n",
      "conclusion: nnnTT\n",
      "\n",
      "infix tree: ( 2 or 3 ) sep 5\n",
      "prefix tree: sep or 2 3 5\n",
      "conclusion: nnTnT,nTnnT\n",
      "\n",
      "infix tree: 2 sep ( 2 and 1 )\n",
      "prefix tree: sep 2 and 2 1\n",
      "conclusion: TTnnn\n",
      "\n",
      "infix tree: not 1 sep ( 3 or 1 )\n",
      "prefix tree: sep not 1 or 3 1\n",
      "conclusion: FnTnn\n",
      "\n",
      "infix tree: not 3 sep ( 2 or 5 )\n",
      "prefix tree: sep not 3 or 2 5\n",
      "conclusion: nnFnT,nTFnn\n",
      "\n",
      "infix tree: ( 4 or 4 ) sep not 2\n",
      "prefix tree: sep or 4 4 not 2\n",
      "conclusion: nFnTn\n",
      "\n",
      "infix tree: 1 sep ( 2 and 2 )\n",
      "prefix tree: sep 1 and 2 2\n",
      "conclusion: TTnnn\n",
      "\n",
      "infix tree: ( 5 and 4 ) sep ( 2 or 4 )\n",
      "prefix tree: sep and 5 4 or 2 4\n",
      "conclusion: nnnTT\n",
      "\n",
      "infix tree: not 3 sep ( 5 or 1 )\n",
      "prefix tree: sep not 3 or 5 1\n",
      "conclusion: nnFnT,TnFnn\n",
      "\n",
      "infix tree: ( 5 and 2 ) sep ( 1 and 3 )\n",
      "prefix tree: sep and 5 2 and 1 3\n",
      "conclusion: TTTnT\n",
      "\n",
      "infix tree: ( 1 or 2 ) sep not 3\n",
      "prefix tree: sep or 1 2 not 3\n",
      "conclusion: nTFnn,TnFnn\n",
      "\n",
      "infix tree: ( 3 or 5 ) sep not 4\n",
      "prefix tree: sep or 3 5 not 4\n",
      "conclusion: nnnFT,nnTFn\n",
      "\n",
      "infix tree: not 3 sep ( 4 and 5 )\n",
      "prefix tree: sep not 3 and 4 5\n",
      "conclusion: nnFTT\n",
      "\n",
      "infix tree: not 5 sep ( 1 and 2 )\n",
      "prefix tree: sep not 5 and 1 2\n",
      "conclusion: TTnnF\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
      "[array([-1.,  0.,  0.,  0.,  1.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([0., 0., 0., 1., 1.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])]\n",
      "[array([0., 0., 1., 0., 1.]), array([0., 1., 0., 0., 1.])]\n",
      "\n",
      "[array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([1., 1., 0., 0., 0.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([-1.,  0.,  1.,  0.,  0.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([ 0.,  0., -1.,  0.,  1.]), array([ 0.,  1., -1.,  0.,  0.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
      "[array([ 0., -1.,  0.,  1.,  0.])]\n",
      "\n",
      "[array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([1., 1., 0., 0., 0.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([0., 0., 0., 1., 1.])]\n",
      "\n",
      "[array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])]\n",
      "[array([ 0.,  0., -1.,  0.,  1.]), array([ 1.,  0., -1.,  0.,  0.])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depth = 2\n",
    "num_variables = 5\n",
    "input_length = 10\n",
    "output_length = 5\n",
    "\n",
    "class SeparatorNode(OperatorNode):\n",
    "    accepts_children = 2\n",
    "\n",
    "    def __init__(self, *children):\n",
    "        super(SeparatorNode, self).__init__('sep', *children)\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        value = self._children[0].evaluate(values)\n",
    "        for child in self._children[1:]:\n",
    "            value = value and child.evaluate(values)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def to_string(self):\n",
    "        string = f'{self._children[0].to_string()}'\n",
    "        for child in self._children[1:]:\n",
    "            string += f' {self._operator_symbol} {child.to_string()}'\n",
    "        return string\n",
    "\n",
    "\n",
    "test_for_one_mental_models = functools.partial(test_for_mental_models, allow_only_one_mental_model=False)\n",
    "# test_for_mental_models_type_two = functools.partial(test_for_mental_models, type_one=False)\n",
    "# test_for_one_mental_models_type_two = functools.partial(test_for_mental_models, type_one=False,\n",
    "#                                                         allow_only_one_mental_model=True)\n",
    "generate_random_sep_tree = functools.partial(generate_random_tree, root_node_cls=SeparatorNode)\n",
    "\n",
    "generate_and_save_trees('./data', 50000, 2, 5,\n",
    "                        test_for_one_mental_models, generate_random_sep_tree,\n",
    "                        base_name='and_trees_single_mms_type_I')\n",
    "\n",
    "encode_mental_models_separated_sentences('./data', 2, 5, 10,\n",
    "                                         'encoded_and_trees_single_mms_type_I',\n",
    "                                         'and_trees_single_mms_type_I')\n",
    "data = load_sentences_and_conclusions('./data', num_variables=5, max_depth=2,\n",
    "                                      base_name='encoded_and_trees_single_mms_type_I')\n",
    "sentences, mental_models, input_dictionary, output_dictionary = data\n",
    "\n",
    "for i in range(10):\n",
    "    print(sentences[i])\n",
    "    print(mental_models[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 7  5  9  1  6]\n",
      "  [ 8  1  0  0  0]]\n",
      "\n",
      " [[ 7  4  9  3  6]\n",
      "  [ 7  5 10  4  6]]\n",
      "\n",
      " [[ 7  2  9  3  6]\n",
      "  [ 5  0  0  0  0]]\n",
      "\n",
      " [[ 2  0  0  0  0]\n",
      "  [ 7  2 10  1  6]]\n",
      "\n",
      " [[ 8  1  0  0  0]\n",
      "  [ 7  3  9  1  6]]]\n",
      "[[[-1  0  0  0  1]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[ 0  0  0  1  1]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[ 0  0  1  0  1]\n",
      "  [ 0  1  0  0  1]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[ 1  1  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]\n",
      "\n",
      " [[-1  0  1  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]\n",
      "  [ 0  0  0  0  0]]]\n",
      "max_input_length 1\n",
      "input (None, 11, 1)\n",
      "input2 (None, 1)\n",
      "embedding_layer (None, 11, 1, 10)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 11, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 11, 1, 10)    110         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 11, 10)       0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, None, 5)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 11, 128), (N 71168       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 128),  68608       input_9[0][0]                    \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 5)      645         lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 140,531\n",
      "Trainable params: 140,531\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "354/354 [==============================] - 6s 10ms/step - loss: 0.0853 - val_loss: 0.0756\n",
      "Epoch 2/3\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0611 - val_loss: 0.0471\n",
      "Epoch 3/3\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0412 - val_loss: 0.0400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-736a718e83b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequences1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-736a718e83b2>\u001b[0m in \u001b[0;36mdecode_sequences1\u001b[1;34m(data, encoder_model, decoder_model)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "def broadcast(x, y):\n",
    "    tf.print(x.shape, y.shape)\n",
    "    x = x[..., np.newaxis]\n",
    "    y = y[..., np.newaxis]\n",
    "    x = np.transpose(x, axes=[0, 2, 1])\n",
    "    y = np.transpose(y, axes=[2, 0, 1])\n",
    "    x, y = np.broadcast_arrays(x, y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def calculate_values(x, y):\n",
    "    s = x + y\n",
    "    sc = np.clip(s, -1, 1)\n",
    "    return sc\n",
    "\n",
    "\n",
    "def calculate_correctness(x, y):\n",
    "    diff = 1 - np.maximum(0, np.abs(x - y) - 1)\n",
    "    prod = np.prod(diff, axis=-1)\n",
    "    return prod\n",
    "\n",
    "\n",
    "def calculate_values_soft(x, y, av=10):\n",
    "    return np.tanh((x + y) * av)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def calculate_correctness_soft(x, y, ac=10):\n",
    "    diff = 1 - sigmoid((np.abs(x - y) - 1.5) * ac)\n",
    "    prod = np.prod(diff, axis=-1)\n",
    "    return prod\n",
    "\n",
    "\n",
    "def calculate_out(values, correctness):\n",
    "    result = values * correctness[..., np.newaxis]\n",
    "    reshaped = np.reshape(result, (result.shape[0] * result.shape[1], result.shape[2]))\n",
    "    return reshaped\n",
    "\n",
    "\n",
    "def combine_mental_models(mm1, mm2):\n",
    "    mm1b, mm2b = broadcast(mm1, mm2)\n",
    "    values = calculate_values(mm1b, mm2b)\n",
    "    correctness = calculate_correctness(mm1b, mm2b)\n",
    "    out = calculate_out(values, correctness)\n",
    "    return out\n",
    "\n",
    "\n",
    "def combine_mental_models_soft(mm1, mm2):\n",
    "    mm1b, mm2b = broadcast(mm1, mm2)\n",
    "    values = calculate_values_soft(mm1b, mm2b, av=10)\n",
    "    correctness = calculate_correctness_soft(mm1b, mm2b, ac=10)\n",
    "    out = calculate_out(values, correctness)\n",
    "    return out\n",
    "\n",
    "\n",
    "def test_mm_inference():\n",
    "    # (a or b)      ---> [T, n], [n, T]\n",
    "    # (a or not b)  ---> [T, n], [n, F]\n",
    "    mm1 = np.array([\n",
    "        [1, 0],\n",
    "        [0, 1],\n",
    "    ])\n",
    "    mm2 = np.array([\n",
    "        [1, 0],\n",
    "        [0, -1]\n",
    "    ])\n",
    "\n",
    "    combined_mental_models = combine_mental_models(mm1, mm2)\n",
    "    combined_mental_models_soft = combine_mental_models_soft(mm1, mm2)\n",
    "    print(combined_mental_models)\n",
    "    print(combined_mental_models_soft)\n",
    "\n",
    "\n",
    "class MMInferenceLayer(kr.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def broadcast(self, x, y):\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        x = tf.transpose(x, perm=[0, 1, 3, 2])\n",
    "        y = tf.transpose(y, perm=[0, 3, 1, 2])\n",
    "        # x = tf.broadcast_to(x, (x.shape[0], x.shape[1]))\n",
    "        # x, y =  np.broadcast_arrays(x, y)\n",
    "        return x, y\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs[0]\n",
    "        y = inputs[1]\n",
    "\n",
    "        x, y = self.broadcast(x, y)\n",
    "\n",
    "        s = x + y\n",
    "        value = tf.clip_by_value(s, -1, 1)\n",
    "        # applicability = (tf.reduce_max(tf.abs(x), axis=-1) * tf.reduce_max(tf.abs(y), axis=-1))\n",
    "        # value = value * tf.expand_dims(applicability, axis=-1)\n",
    "\n",
    "        diff = 1 - tf.maximum(0., tf.abs(x - y) - 1.)\n",
    "        correctness = tf.reduce_prod(diff, axis=-1)\n",
    "        mms = value * tf.expand_dims(correctness, axis=-1)\n",
    "        reshaped_value = tf.reshape(mms, (-1, mms.shape[-3] * mms.shape[-2], mms.shape[-1]))\n",
    "        reshaped_correctness = tf.reshape(correctness, (-1, correctness.shape[-2] * correctness.shape[-1]))\n",
    "        mm = tf.reduce_sum(reshaped_value, axis=-2)\n",
    "        mm = mm / tf.reduce_sum(reshaped_correctness, axis=-1, keepdims=True)\n",
    "        # mm = tf.clip_by_value(mm, -1, 1)\n",
    "        # mm = tf.tanh(mm)\n",
    "        return mm\n",
    "\n",
    "\n",
    "def create_inference_model(num_variables, max_input_length, max_sub_mental_models):\n",
    "    embedding_size = 10\n",
    "    hidden_units = 128\n",
    "    print('max_input_length', max_input_length)\n",
    "    input = kr.Input(shape=(2, max_input_length))\n",
    "    split_layer = kr.layers.Lambda(lambda x: (x[:, 0], x[:, 1]))(input)\n",
    "\n",
    "    nn_input = kr.Input(max_input_length)\n",
    "    nn_embedding_layer = kr.layers.Embedding(num_symbols + 1, embedding_size)(nn_input);print(nn_embedding_layer)\n",
    "    flatten_layer = kr.layers.Flatten()(nn_embedding_layer);print(flatten_layer.shape)\n",
    "    nn_hidden = kr.layers.Dense(hidden_units, activation='relu')(flatten_layer)\n",
    "    nn_output = kr.layers.Dense(num_variables * max_sub_mental_models,\n",
    "                                activation='tanh',\n",
    "                                activity_regularizer=kr.regularizers.L1(0.0))(nn_hidden)\n",
    "    nn_reshape = kr.layers.Reshape((max_sub_mental_models, num_variables))(nn_output)\n",
    "    sub_sequence_nn = kr.Model(inputs=nn_input, outputs=nn_reshape, name='sub-sequence-NN')\n",
    "    sub_sequence_nn.summary()\n",
    "\n",
    "    mm = sub_sequence_nn(split_layer[0]), sub_sequence_nn(split_layer[1])\n",
    "    mm_inference_layer = MMInferenceLayer()(mm)\n",
    "\n",
    "    model = kr.Model(inputs=input, outputs=mm_inference_layer)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_varying_inference_model1(num_variables, max_input_length):\n",
    "    # Without specific token for start of sequence (index 0) and end of sequence (index 1) - (0,0,0,0,0) equals end\n",
    "    # Initialise parameters\n",
    "    embedding_size = 10\n",
    "    hidden_units = 128\n",
    "    print('max_input_length', max_input_length)\n",
    "    \n",
    "    # Create input for encoder\n",
    "    encoder_inputs = kr.Input(shape=(2, max_input_length))\n",
    "\n",
    "    print('input',encoder_inputs.shape)\n",
    "    \n",
    "    # Make model - Encoder (flatten / concatenate subsentences to one vector (subsentence representation))\n",
    "    nn_input = kr.Input(shape=(num_variables))\n",
    "    nn_embedding_layer = kr.layers.Embedding(num_symbols+1, embedding_size)(encoder_inputs)\n",
    "    nn_flatten = tf.keras.layers.Reshape((nn_embedding_layer.shape[1],-1))(nn_embedding_layer)\n",
    "    encoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    encoder_outputs, state_h, state_c = encoder(nn_flatten)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Create decoder\n",
    "    decoder_inputs = kr.Input(shape=(None,num_variables))\n",
    "    decoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    decoder_outputs, _, _ = decoder(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = kr.layers.Dense(num_variables, activation='tanh')\n",
    "    output = decoder_dense(decoder_outputs)\n",
    "\n",
    "    ## Define training model\n",
    "    model_train = kr.Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
    "    model_train.summary()\n",
    "    \n",
    "    ## Train model \n",
    "    model_train.compile(optimizer=kr.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=kr.losses.mse)\n",
    "\n",
    "    callbacks = [kr.callbacks.EarlyStopping(patience=20, min_delta=1e-5, restore_best_weights=True)]\n",
    "    history = model_train.fit([ds.x_train, ds.y_train_d], ds.y_train, validation_data=([ds.x_valid, ds.y_valid_d], ds.y_valid),\n",
    "                        epochs=3, batch_size=8, callbacks=callbacks)\n",
    "    \n",
    "    ## Define testing models (no teacher forcing)\n",
    "    encoder_model = kr.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = kr.Input(shape=(hidden_units,))\n",
    "    decoder_state_input_c = kr.Input(shape=(hidden_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = kr.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "\n",
    "    # Returned trained models, and history of training\n",
    "    return model_train, history, encoder_model, decoder_model\n",
    "\n",
    "def create_varying_inference_model2(num_variables, max_input_length):\n",
    "    # With specific token for start of sequence (index 0) and end of sequence (index 1)\n",
    "    # Initialise parameters\n",
    "    embedding_size = 10\n",
    "    hidden_units = 128\n",
    "    print('max_input_length', max_input_length)\n",
    "    # Create input for encoder\n",
    "    encoder_inputs = kr.Input(shape=(2, max_input_length))\n",
    "\n",
    "    print('input',encoder_inputs.shape)\n",
    "    \n",
    "    # Make model - Encoder (flatten / concatenate subsentences to one vector (subsentence representation))\n",
    "    nn_input = kr.Input(shape=(num_variables))\n",
    "    nn_embedding_layer = kr.layers.Embedding(num_symbols+1, embedding_size)(encoder_inputs)\n",
    "    nn_flatten = tf.keras.layers.Reshape((nn_embedding_layer.shape[1],-1))(nn_embedding_layer)\n",
    "    encoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    encoder_outputs, state_h, state_c = encoder(nn_flatten)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Create decoder\n",
    "    decoder_inputs = kr.Input(shape=(None,num_variables+2))\n",
    "    decoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    decoder_outputs, _, _ = decoder(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = kr.layers.Dense(num_variables+2, activation='tanh')\n",
    "    output = decoder_dense(decoder_outputs)\n",
    "\n",
    "    ## Define training model\n",
    "    model_train = kr.Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
    "    model_train.summary()\n",
    "    \n",
    "    ## Train model \n",
    "    model_train.compile(optimizer=kr.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=kr.losses.mse)\n",
    "\n",
    "    callbacks = [kr.callbacks.EarlyStopping(patience=20, min_delta=1e-5, restore_best_weights=True)]\n",
    "    history = model_train.fit([ds.x_train, ds.y_train_d], ds.y_train, validation_data=([ds.x_valid, ds.y_valid_d], ds.y_valid),\n",
    "                        epochs=1000, batch_size=8, callbacks=callbacks)\n",
    "    \n",
    "    ## Define testing models (no teacher forcing)\n",
    "    encoder_model = kr.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = kr.Input(shape=(hidden_units,))\n",
    "    decoder_state_input_c = kr.Input(shape=(hidden_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = kr.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "\n",
    "    # Returned trained models, and history of training\n",
    "    return model_train, history, encoder_model, decoder_model\n",
    "\n",
    "def create_varying_inference_model3(num_variables, max_input_length):\n",
    "    # Without specific token for start of sequence (index 0) and end of sequence (index 1) - (0,0,0,0,0) equals end\n",
    "    # Based on characters instead of subsentences\n",
    "    # Initialise parameters\n",
    "    embedding_size = 10\n",
    "    hidden_units = 128\n",
    "    print('max_input_length', max_input_length)\n",
    "    \n",
    "    # Create input for encoder\n",
    "    encoder_inputs = kr.Input(shape=(11, max_input_length))\n",
    "\n",
    "    print('input',encoder_inputs.shape)\n",
    "    \n",
    "    # Make model - Encoder (flatten / concatenate subsentences to one vector (subsentence representation))\n",
    "    nn_input = kr.Input(shape=(1))\n",
    "    print('input2', nn_input.shape)\n",
    "    nn_embedding_layer = kr.layers.Embedding(num_symbols+1, embedding_size)(encoder_inputs)\n",
    "    nn_flatten = tf.keras.layers.Reshape((nn_embedding_layer.shape[1],-1))(nn_embedding_layer)\n",
    "    print('embedding_layer', nn_embedding_layer.shape)\n",
    "    encoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    encoder_outputs, state_h, state_c = encoder(nn_flatten)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Create decoder\n",
    "    decoder_inputs = kr.Input(shape=(None,num_variables))\n",
    "    decoder = kr.layers.LSTM(hidden_units, return_sequences=True, return_state=True, activation='relu')\n",
    "    decoder_outputs, _, _ = decoder(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = kr.layers.Dense(num_variables, activation='tanh')\n",
    "    output = decoder_dense(decoder_outputs)\n",
    "\n",
    "    ## Define training model\n",
    "    model_train = kr.Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
    "    model_train.summary()\n",
    "    \n",
    "    ## Train model \n",
    "    model_train.compile(optimizer=kr.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=kr.losses.mse)\n",
    "\n",
    "    callbacks = [kr.callbacks.EarlyStopping(patience=20, min_delta=1e-5, restore_best_weights=True)]\n",
    "    history = model_train.fit([ds.x_train, ds.y_train_d], ds.y_train, validation_data=([ds.x_valid, ds.y_valid_d], ds.y_valid),\n",
    "                        epochs=3, batch_size=8, callbacks=callbacks)\n",
    "    \n",
    "    ## Define testing models (no teacher forcing)\n",
    "    encoder_model = kr.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = kr.Input(shape=(hidden_units,))\n",
    "    decoder_state_input_c = kr.Input(shape=(hidden_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = kr.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "\n",
    "    # Returned trained models, and history of training\n",
    "    return model_train, history, encoder_model, decoder_model\n",
    "\n",
    "def decode_sequence1(input_seq, encoder_model, decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_variables))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_output = target_seq\n",
    "    while not stop_condition:\n",
    "        output, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Save MMs\n",
    "        pred = np.rint(output).astype(int)\n",
    "        decoded_output = np.concatenate((decoded_output, pred), axis=1)\n",
    "\n",
    "        # Exit condition: hit max length\n",
    "        # this padding, such that all arrays have the same size in decoded_output.\n",
    "        if decoded_output.shape[1] > num_variables:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = pred\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_output[:,1:,:]\n",
    "\n",
    "def decode_sequence2(input_seq, encoder_model, decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_variables+2))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_output = target_seq\n",
    "    while not stop_condition:\n",
    "        output, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Save MMs\n",
    "        pred = np.rint(output).astype(int)\n",
    "        decoded_output = np.concatenate((decoded_output, pred), axis=1)\n",
    "\n",
    "        # Exit condition: hit max length\n",
    "        # this padding, such that all arrays have the same size in decoded_output.\n",
    "        if decoded_output.shape[1] > num_variables:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = pred\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_output[:,1:,:]\n",
    "\n",
    "def decode_sequences1(data, encoder_model, decoder_model):\n",
    "    preds = decode_sequence1(data[[0]], encoder_model, decoder_model)\n",
    "    for i in range(1,ds.x_test.shape[0]):\n",
    "        pred = decode_sequence1(data[[i]], encoder_model, decoder_model)\n",
    "        preds = np.concatenate((preds, pred), axis=0)\n",
    "        print(i)\n",
    "        \n",
    "    return preds\n",
    "\n",
    "def decode_sequences2(data, encoder_model, decoder_model):\n",
    "    preds = decode_sequence2(data[[0]], encoder_model, decoder_model)\n",
    "    for i in range(1,ds.x_test.shape[0]):\n",
    "        pred = decode_sequence2(data[[i]], encoder_model, decoder_model)\n",
    "        preds = np.concatenate((preds, pred), axis=0)\n",
    "        print(i)\n",
    "        \n",
    "    return preds\n",
    "\n",
    "def two_way_mse(y_true, y_pred):\n",
    "    y_true_float = tf.cast(y_true, y_pred.dtype)\n",
    "    diff = (y_true_float - y_pred) ** 2\n",
    "    print(diff)\n",
    "    return tf.reduce_mean(diff)\n",
    "\n",
    "\n",
    "def show_subsentence_inference(model, ds, decoding_dictionary, idxs):\n",
    "    sub_model = model.layers[2]\n",
    "    for i in idxs:\n",
    "        for j in range(2):\n",
    "            x = ds.x_test[i][j]\n",
    "            pred = sub_model.predict(x[np.newaxis, ...])\n",
    "            print(dataset.encoding.decode_sentence(x, decoding_dictionary, ds.indexed_encoding))\n",
    "            print(np.rint(pred))\n",
    "            \n",
    "def add_zero_row1(data, position):\n",
    "    if position == 'front':\n",
    "        temp = np.zeros((data.shape[0],data.shape[1]+1,data.shape[2]))\n",
    "        temp[:,1:,:] = data\n",
    "    elif position == 'last':\n",
    "        temp = np.zeros((data.shape[0],data.shape[1]+1,data.shape[2]))\n",
    "        temp[:,:-1,:] = data\n",
    "\n",
    "    return temp\n",
    "\n",
    "def add_zero_row2(dst, position):\n",
    "    start_vec = np.array([1,0] + [0] * (num_variables))\n",
    "    end_vec = np.array([0,1] + [0] * (num_variables))\n",
    "    if position == 'front':\n",
    "        data = np.zeros((dst.shape[0], dst.shape[1]+1, dst.shape[2]+2))\n",
    "        data[:,1:,2:] = dst\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i][data[i].sum(axis=1) == 0] = end_vec\n",
    "            data[i][0,:] = start_vec\n",
    "    elif position == 'last':\n",
    "        data = np.zeros((dst.shape[0], dst.shape[1]+1, dst.shape[2]+2))\n",
    "        data[:,:-1,2:] = dst\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i][data[i].sum(axis=1) == 0] = end_vec\n",
    "            data[i][-1,:] = end_vec\n",
    "        \n",
    "    return data\n",
    "\n",
    "def concat_subsentences(data):\n",
    "    temp = np.array(data[0][0].tolist() + [10] + data[0][1].tolist())[np.newaxis, ...]\n",
    "    for i in range(1,data.shape[0]):\n",
    "        sentence = np.array(data[i][0].tolist() + [10] + data[i][1].tolist())[np.newaxis, ...]\n",
    "        temp = np.concatenate((temp, sentence), axis=0)\n",
    "    \n",
    "    return temp[..., np.newaxis]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ds = get_separated_sequences_mental_models_dataset('./data', 'encoded_and_trees_single_mms_type_I',\n",
    "                                                       num_variables=5, max_depth=2,\n",
    "                                                       test_size=.1, valid_size=.1,\n",
    "                                                       indexed_encoding=True, pad_mental_models=True)\n",
    "\n",
    "    dec_in, dec_out = dataset.encoding.create_decoding_dictionaries(ds.input_dictionary, ds.output_dictionary)\n",
    "\n",
    "    ds.y_train_d = add_zero_row1(ds.y_train, 'front')\n",
    "    ds.y_train = add_zero_row1(ds.y_train, 'last')\n",
    "    ds.y_valid_d = add_zero_row1(ds.y_valid, 'front')\n",
    "    ds.y_valid = add_zero_row1(ds.y_valid, 'last')\n",
    "    ds.y_test_d = add_zero_row1(ds.y_test, 'front')\n",
    "    ds.y_test = add_zero_row1(ds.y_test, 'last')\n",
    "    \n",
    "    ds.x_train = concat_subsentences(ds.x_train)\n",
    "    ds.x_valid = concat_subsentences(ds.x_valid)\n",
    "    ds.x_test = concat_subsentences(ds.x_test)\n",
    "    \n",
    "    num_variables = 5\n",
    "    num_operators = 5  # and, or, not\n",
    "    num_symbols = num_variables + num_operators\n",
    "    max_input_length = ds.x_train.shape[-1]\n",
    "    \n",
    "    # 1: subsentences no index, 2: subsentences index, 3: symbols no index\n",
    "    model_train, history, encoder_model, decoder_model = create_varying_inference_model3(num_variables, \n",
    "                                                                                        max_input_length)\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(range(len(loss)), loss, label='loss')\n",
    "    plt.plot(range(len(val_loss)), loss, label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    preds = decode_sequences1(ds.x_test, encoder_model, decoder_model)\n",
    "    for i in range(preds.shape[0]):\n",
    "        print(preds[i], ds.y_test[i])\n",
    "\n",
    "    print('errors:')\n",
    "    for i in range(preds.shape[0]):\n",
    "        if np.sum(np.abs(preds[i] - ds.y_test[i])) == 0:\n",
    "            continue\n",
    "        print(dataset.encoding.decode_sentence(ds.x_test[i][0], dec_in, ds.indexed_encoding))\n",
    "        print(dataset.encoding.decode_sentence(ds.x_test[i][1], dec_in, ds.indexed_encoding))\n",
    "        print(ds.y_test[i])\n",
    "        print(preds[i])\n",
    "        print()\n",
    "\n",
    "    errors = np.count_nonzero(np.sum(np.abs(preds - ds.y_test), axis=-1))\n",
    "    print('errors', int(errors))\n",
    "    print(f'accuracy: {int((1 - int(errors)/ds.x_test.shape[0]) * 1000) / 10}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" A GRU-based encoder. \"\"\"\n",
    "    def __init__(self, input_vocab_size, hidden_size, emb_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_vocab_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        if hidden is not None:  # Update hidden states step by step\n",
    "            embedded = self.embedding(input).view(1, 1, -1)\n",
    "            output = embedded\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        else:   # In case we only need the last state\n",
    "            embedded = self.embedding(input).view(len(input), 1, -1)\n",
    "            output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        '''Initialize hidden state'''\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\" A GRU-based decoder. \"\"\"\n",
    "    def __init__(self, hidden_size, output_vocab_size, emb_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_vocab_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Output word embedding\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        # Update decoder hidden state\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Distribution over output vocabulary\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        '''Initialize hidden state'''\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2ac01a8b932a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Train for 3 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msrc_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "input_size = sentences[0][0].shape[1]\n",
    "output_size = mental_models[0][0].size\n",
    "hidden_size = 128\n",
    "report_every = 1000\n",
    "\n",
    "# Initialize encoder and decoder\n",
    "enc = Encoder(input_size, hidden_size, emb_size=8)\n",
    "dec = Decoder(hidden_size, output_size, emb_size=8)\n",
    "\n",
    "# Initialize the optimizers\n",
    "enc_optimizer = optim.Adam(enc.parameters())\n",
    "dec_optimizer = optim.Adam(dec.parameters())\n",
    "loss_function = nn.NLLLoss()\n",
    "print_loss_total = 0\n",
    "\n",
    "for epoch in range(1, 4):  # Train for 3 epochs\n",
    "    random.shuffle(tensor_dataset)\n",
    "    for i, instance in enumerate(tensor_dataset):\n",
    "        src_sequence, tgt_sequence = instance[0], instance[1]\n",
    "        _, last_enc_state = enc(src_sequence)\n",
    "        # Create BOS token - First decoder input is the start token \n",
    "        decoder_input = torch.tensor([[generator.token_to_idx['<s>']]], device=device)\n",
    "        # First decoder hidden state is the last encoder hidden state\n",
    "        decoder_hidden = last_enc_state\n",
    "        loss = 0\n",
    "\n",
    "        # For each decoder timestep\n",
    "        for i_decoder in range(len(tgt_sequence)):\n",
    "            # Feed decoder input to decoder hidden state. Also feed in encoder outputs for calculating context\n",
    "            decoder_output, decoder_hidden = dec(decoder_input, decoder_hidden)\n",
    "            loss += loss_function(decoder_output, tgt_sequence[i_decoder])\n",
    "            # When training, use the correct label at this step at input to the decoder \n",
    "            decoder_input = tgt_sequence[i_decoder]\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "        enc.zero_grad()\n",
    "        dec.zero_grad()\n",
    "\n",
    "        print_loss_total += loss.item() / len(tgt_sequence)\n",
    "\n",
    "        if (i != 0 and i % report_every == 0) or i == len(tensor_dataset)-1:\n",
    "            print('Epoch {0}: trained {1} input-output pairs, loss {2:.4f}'.format(epoch, i, print_loss_total / report_every))\n",
    "            print_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 10\n",
    "n_correct = 0\n",
    "input_min_val = 10\n",
    "input_max_val = 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n_tests):\n",
    "        test_pair = generator.generate_equation(input_min_val, input_max_val)\n",
    "        input_seq = tensor_from_character_sequence(test_pair[0], generator.token_to_idx)\n",
    "\n",
    "        _, last_enc_state = enc(input_seq)\n",
    "\n",
    "        # Create BOS token - First decoder input is the start token \n",
    "        decoder_input = torch.tensor([generator.token_to_idx['<s>']], device=device)\n",
    "        # First decoder hidden state is the last encoder hidden state\n",
    "        decoder_hidden = last_enc_state\n",
    "\n",
    "        decoded_words = []\n",
    "        # For each decoder timestep\n",
    "        for i_decoder in range(10):\n",
    "            # Feed decoder input to decoder hidden state. Also feed in encoder outputs for calculating context\n",
    "            decoder_output, decoder_hidden = dec(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "            if topi.item() == generator.token_to_idx['</s>']:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(generator.idx_to_token[topi.item()])\n",
    "            # When testing, use the model prediction\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        model_output = ''.join(decoded_words)\n",
    "\n",
    "        if model_output == test_pair[1]:\n",
    "            n_correct += 1\n",
    "            marker = ''\n",
    "        else:\n",
    "            marker = '<--------'\n",
    "        print('Input:\\t', test_pair[0])\n",
    "        print('Model output:\\t', model_output, marker)\n",
    "        print('Ground truth:\\t', test_pair[1], '\\n')\n",
    "\n",
    "    print('{0}/{1}, correct rate: {2:0.0%}'.format(n_correct, n_tests, n_correct/n_tests))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
